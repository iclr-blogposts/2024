<!DOCTYPE html> <html> <script>let thunk=()=>{let e=e=>e.trim(),t=e=>e.innerText,a=e=>{let t=e.split(" "),a=t.slice(0,-1).join(" ");return[t.at(-1),a]},n=Array.from(document.getElementsByClassName("author")).map(t).map(e).map(a),o=n[0][0],i=(Array.from(document.getElementsByClassName("affiliation")).filter(e=>"P"===e.nodeName).map(t).map(e),"May 7, 2024"),r="Towards Robust Foundation Models: Adversarial Contrastive Learning",s="Foundation models pre-trained on large-scale unlabelled datasets using self-supervision can be generalizable to a wide range of downstream tasks. Existing work has shown that adversarial attacks can effectively fool any downstream models fine-tuned from a pre-trained foundation model. The existence of such adversarial attacks necessitates the development of robust foundation models which can yield both standard generalization and adversarial robustness to safety-critical downstream tasks. Currently, adversarial contrastive learning (ACL) is one of the most effective methods for outputting a robust foundation model. ACL incorporates contrastive learning with adversarial data to effectively output a robust representation without requiring costly annotations. In this blog, we introduced two NeurIPS 2023 publications that can enhance ACL's efficacy and efficiency, respectively. (1) This blog introduces Adversarial Invariant Regularization (AIR) which is a state-of-the-art ACL algorithm. A causal theoretical framework is built to interpret ACL, and then the AIR algorithm is derived from the causal framework to regulate and improve the ACL. (2) This blog also introduces a Robustness-aware Coreset Selection (RCS) method to speed up ACL. RCS does not require label information and searches for an informative training subset that can maintain the adversarial robustness. For the first time, RCS enables the application of ACL on the large-scale ImageNet-1K dataset.";{let e=n.map(e=>`${e[0]}, ${e[1]}`).join(" and "),t=`\n@inproceedings{${(o+"2024"+r.split(" ").slice(0,3).join("")).replace(" ","").replace(/[\p{P}$+<=>^`|~]/gu,"").toLowerCase().trim()},\n  author = {${e}},\n  title = {${r}},\n  abstract = {${s}},\n  booktitle = {ICLR Blogposts 2024},\n  year = {2024},\n  date = {${i}},\n  note = {${window.location.href}},\n  url  = {${window.location.href}}\n}\n  `.trim();document.getElementById("bibtex-box").innerText=t}{let e=n.map(e=>e[0]),t=`\n${e=e.length>2?e[0]+", et al.":2==e.length?e[0]+" & "+e[1]:e[0]}, "${r}", ICLR Blogposts, 2024.\n`.trim();document.getElementById("bibtex-academic-attribution").innerText=t}};document.addEventListener("readystatechange",function(){"complete"===document.readyState&&thunk()});</script> <head> <meta charset="utf-8"> <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no"> <meta http-equiv="X-UA-Compatible" content="IE=edge"> <title>Towards Robust Foundation Models: Adversarial Contrastive Learning | ICLR Blogposts 2024</title> <meta name="author" content="ICLR Blog"/> <meta name="description" content="Foundation models pre-trained on large-scale unlabelled datasets using self-supervision can be generalizable to a wide range of downstream tasks. Existing work has shown that adversarial attacks can effectively fool any downstream models fine-tuned from a pre-trained foundation model. The existence of such adversarial attacks necessitates the development of robust foundation models which can yield both standard generalization and adversarial robustness to safety-critical downstream tasks. Currently, adversarial contrastive learning (ACL) is one of the most effective methods for outputting a robust foundation model. ACL incorporates contrastive learning with adversarial data to effectively output a robust representation without requiring costly annotations. In this blog, we introduced two NeurIPS 2023 publications that can enhance ACL's efficacy and efficiency, respectively. (1) This blog introduces Adversarial Invariant Regularization (AIR) which is a state-of-the-art ACL algorithm. A causal theoretical framework is built to interpret ACL, and then the AIR algorithm is derived from the causal framework to regulate and improve the ACL. (2) This blog also introduces a Robustness-aware Coreset Selection (RCS) method to speed up ACL. RCS does not require label information and searches for an informative training subset that can maintain the adversarial robustness. For the first time, RCS enables the application of ACL on the large-scale ImageNet-1K dataset."/> <meta name="keywords" content="machine-learning, ml, deep-learning, reinforcement-learning, iclr"/> <link href="https://cdn.jsdelivr.net/npm/bootstrap@4.6.1/dist/css/bootstrap.min.css" rel="stylesheet" integrity="sha256-DF7Zhf293AJxJNTmh5zhoYYIMs2oXitRfBjY+9L//AY=" crossorigin="anonymous"> <link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/mdbootstrap@4.20.0/css/mdb.min.css" integrity="sha256-jpjYvU3G3N6nrrBwXJoVEYI/0zw8htfFnhT9ljN3JJw=" crossorigin="anonymous"/> <link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/@fortawesome/fontawesome-free@5.15.4/css/all.min.css" integrity="sha256-mUZM63G8m73Mcidfrv5E+Y61y7a12O5mW4ezU3bxqW4=" crossorigin="anonymous"> <link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/academicons@1.9.1/css/academicons.min.css" integrity="sha256-i1+4qU2G2860dGGIOJscdC30s9beBXjFfzjWLjBRsBg=" crossorigin="anonymous"> <link rel="stylesheet" type="text/css" href="https://fonts.googleapis.com/css?family=Roboto:300,400,500,700|Roboto+Slab:100,300,400,500,700|Material+Icons"> <link rel="stylesheet" href="https://cdn.jsdelivr.net/gh/jwarby/jekyll-pygments-themes@master/github.css" media="" id="highlight_theme_light"/> <link rel="shortcut icon" href="/2024/assets/img/iclr_favicon.ico"/> <link rel="stylesheet" href="/2024/assets/css/main.css"> <link rel="canonical" href="https://iclr-blogposts.github.io/2024/blog/robust-foundation-model/"> <link rel="stylesheet" href="https://cdn.jsdelivr.net/gh/jwarby/jekyll-pygments-themes@master/native.css" media="none" id="highlight_theme_dark"/> <script src="/2024/assets/js/theme.js"></script> <script src="/2024/assets/js/dark_mode.js"></script> <script src="https://cdn.jsdelivr.net/npm/jquery@3.6.0/dist/jquery.min.js" integrity="sha256-/xUj+3OJU5yExlq6GSYGSHk7tPXikynS7ogEvDej/m4=" crossorigin="anonymous"></script> <script type="text/javascript">window.MathJax={tex:{tags:"ams"}};</script> <script defer type="text/javascript" id="MathJax-script" src="https://cdn.jsdelivr.net/npm/mathjax@3.2.0/es5/tex-mml-chtml.js"></script> <script defer src="https://polyfill.io/v3/polyfill.min.js?features=es6"></script> <script src="/2024/assets/js/distillpub/template.v2.js"></script> <script src="/2024/assets/js/distillpub/transforms.v2.js"></script> <script src="/2024/assets/js/distillpub/overrides.js"></script> <style type="text/css">.fake-img{background:#bbb;border:1px solid rgba(0,0,0,0.1);box-shadow:0 0 4px rgba(0,0,0,0.1);margin-bottom:12px}.fake-img p{font-family:monospace;color:white;text-align:left;margin:12px 0;text-align:center;font-size:16px}</style> </head> <d-front-matter> <script async type="text/json">{
      "title": "Towards Robust Foundation Models: Adversarial Contrastive Learning",
      "description": "Foundation models pre-trained on large-scale unlabelled datasets using self-supervision can be generalizable to a wide range of downstream tasks. Existing work has shown that adversarial attacks can effectively fool any downstream models fine-tuned from a pre-trained foundation model. The existence of such adversarial attacks necessitates the development of robust foundation models which can yield both standard generalization and adversarial robustness to safety-critical downstream tasks. Currently, adversarial contrastive learning (ACL) is one of the most effective methods for outputting a robust foundation model. ACL incorporates contrastive learning with adversarial data to effectively output a robust representation without requiring costly annotations. In this blog, we introduced two NeurIPS 2023 publications that can enhance ACL's efficacy and efficiency, respectively. (1) This blog introduces Adversarial Invariant Regularization (AIR) which is a state-of-the-art ACL algorithm. A causal theoretical framework is built to interpret ACL, and then the AIR algorithm is derived from the causal framework to regulate and improve the ACL. (2) This blog also introduces a Robustness-aware Coreset Selection (RCS) method to speed up ACL. RCS does not require label information and searches for an informative training subset that can maintain the adversarial robustness. For the first time, RCS enables the application of ACL on the large-scale ImageNet-1K dataset.",
      "published": "May 7, 2024",
      "authors": [
        {
          "author": "Jingfeng Zhang",
          "authorURL": "https://zjfheart.github.io/",
          "affiliations": [
            {
              "name": "The University of Auckland & RIKEN Center for Advanced Intelligence Project",
              "url": ""
            }
          ]
        },
        {
          "author": "Xilie Xu",
          "authorURL": "https://godxuxilie.github.io/",
          "affiliations": [
            {
              "name": "National University of Singapore",
              "url": ""
            }
          ]
        }
        
      ],
      "katex": {
        "delimiters": [
          {
            "left": "$",
            "right": "$",
            "display": false
          },
          {
            "left": "$$",
            "right": "$$",
            "display": true
          }
        ]
      }
    }</script> </d-front-matter> <body class="fixed-top-nav"> <header> <nav id="navbar" class="navbar navbar-light navbar-expand-sm fixed-top"> <div class="container"> <a class="navbar-brand title font-weight-lighter" href="/2024/">ICLR Blogposts 2024</a> <button class="navbar-toggler collapsed ml-auto" type="button" data-toggle="collapse" data-target="#navbarNav" aria-controls="navbarNav" aria-expanded="false" aria-label="Toggle navigation"> <span class="sr-only">Toggle navigation</span> <span class="icon-bar top-bar"></span> <span class="icon-bar middle-bar"></span> <span class="icon-bar bottom-bar"></span> </button> <div class="collapse navbar-collapse text-right" id="navbarNav"> <ul class="navbar-nav ml-auto flex-nowrap"> <li class="nav-item "> <a class="nav-link" href="/2024/about/">about</a> </li> <li class="nav-item "> <a class="nav-link" href="/2024/call/">call for blogposts</a> </li> <li class="nav-item "> <a class="nav-link" href="/2024/submitting/">submitting</a> </li> <li class="nav-item "> <a class="nav-link" href="/2024/reviewing/">reviewing</a> </li> <li class="nav-item "> <a class="nav-link" href="/2024/blog/index.html">blog</a> </li> <li class="nav-item dropdown "> <a class="nav-link dropdown-toggle" href="#" id="navbarDropdown" role="button" data-toggle="dropdown" aria-haspopup="true" aria-expanded="false">other iterations</a> <div class="dropdown-menu dropdown-menu-right" aria-labelledby="navbarDropdown"> <a class="dropdown-item" href="https://iclr-blogposts.github.io/2025/">2025</a> <div class="dropdown-divider"></div> <a class="dropdown-item" href="https://iclr-blogposts.github.io/2024/"><strong>2024</strong></a> <div class="dropdown-divider"></div> <a class="dropdown-item" href="https://iclr-blogposts.github.io/2023/">2023</a> <div class="dropdown-divider"></div> <a class="dropdown-item" href="https://iclr-blog-track.github.io/home/" target="_blank" rel="noopener noreferrer">2022</a> </div> </li> <li class="toggle-container"> <button id="light-toggle" title="Change theme"> <i class="fas fa-moon"></i> <i class="fas fa-sun"></i> </button> </li> </ul> </div> </div> </nav> </header> <div class="post distill"> <d-title> <h1>Towards Robust Foundation Models: Adversarial Contrastive Learning</h1> <p>Foundation models pre-trained on large-scale unlabelled datasets using self-supervision can be generalizable to a wide range of downstream tasks. Existing work has shown that adversarial attacks can effectively fool any downstream models fine-tuned from a pre-trained foundation model. The existence of such adversarial attacks necessitates the development of robust foundation models which can yield both standard generalization and adversarial robustness to safety-critical downstream tasks. Currently, adversarial contrastive learning (ACL) is one of the most effective methods for outputting a robust foundation model. ACL incorporates contrastive learning with adversarial data to effectively output a robust representation without requiring costly annotations. In this blog, we introduced two NeurIPS 2023 publications that can enhance ACL's efficacy and efficiency, respectively. (1) This blog introduces Adversarial Invariant Regularization (AIR) which is a state-of-the-art ACL algorithm. A causal theoretical framework is built to interpret ACL, and then the AIR algorithm is derived from the causal framework to regulate and improve the ACL. (2) This blog also introduces a Robustness-aware Coreset Selection (RCS) method to speed up ACL. RCS does not require label information and searches for an informative training subset that can maintain the adversarial robustness. For the first time, RCS enables the application of ACL on the large-scale ImageNet-1K dataset.</p> </d-title> <d-byline></d-byline> <d-article> <d-contents> <nav class="l-text figcaption"> <h3>Contents</h3> <div><a href="#foundation-models">Foundation Models</a></div> <ul> <li><a href="#contrastive-learning-cl">Contrastive Learning (CL)</a></li> </ul> <div><a href="#robust-foundation-models">Robust Foundation Models</a></div> <ul> <li><a href="#adversarial-contrastive-learning-acl">Adversarial Contrastive Learning (ACL)</a></li> </ul> <div><a href="#enhancing-acl-via-adversarial-invariant-regularization-air">Enhancing ACL via Adversarial Invariant Regularization (AIR)</a></div> <ul> <li><a href="#causal-view-of-acl">Causal View of ACL</a></li> <li><a href="#the-methodology-of-air">the Methodology of AIR</a></li> <li><a href="#empirical-results">Empirical Results</a></li> <li><a href="#robust-self-supervised-learning-robustssl-benchmark">Robust Self-Supervised Learning (RobustSSL) Benchmark</a></li> </ul> <div><a href="#efficient-acl-via-robustness-aware-coreset-selection-rcs">Efficient ACL via Robustness-Aware Coreset Selection (RCS)</a></div> <ul> <li><a href="#motivation-acl-is-inefficient">Motivation---ACL is Inefficient</a></li> <li><a href="#the-methodology-of-rcs">the Methodology of RCS</a></li> <li><a href="#experimental-results">Experimental Results</a></li> </ul> </nav> </d-contents> <h2 id="foundation-models">Foundation Models</h2> <p>Foundation models <d-cite key="bommasani2021opportunities"></d-cite> are pre-trained on large-scale unlabelled datasets using self-supervised learning methods, which is generalizable to a wide range of downstream tasks via fine-tuning. For example, GPT-3 <d-cite key="GPT-3"></d-cite> has been successfully commercialized as a powerful text generation application. Vision transformer <d-cite key="ViT"></d-cite> has been widely used in computer vision tasks such as object detection <d-cite key="ViT-object-detection"></d-cite> and medical analysis <d-cite key="ViT-medical-analysis"></d-cite>. BLIP <d-cite key="BLIP"></d-cite> is a vision-language pre-trained model that can perform many vision-language tasks such as the visual question answering task <d-cite key="VQA"></d-cite>. CLAP <d-cite key="CLAP"></d-cite> is a language-audio pre-trained model that can be used for understanding the pair of texts and audio.</p> <div class="row mt-3"> <div class="col-sm mt-3 mt-md-0"> <figure> <picture> <source class="responsive-img-srcset" media="(max-width: 480px)" srcset="/2024/assets/img/2024-05-07-robust-foundation-model/foundation_models-480.webp"></source> <source class="responsive-img-srcset" media="(max-width: 800px)" srcset="/2024/assets/img/2024-05-07-robust-foundation-model/foundation_models-800.webp"></source> <source class="responsive-img-srcset" media="(max-width: 1400px)" srcset="/2024/assets/img/2024-05-07-robust-foundation-model/foundation_models-1400.webp"></source> <img src="/2024/assets/img/2024-05-07-robust-foundation-model/foundation_models.png" class="img-fluid" width="auto" height="auto" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"> </picture> </figure> </div> </div> <h3 id="contrastive-learning-cl">Contrastive Learning (CL)</h3> <p>To build foundation models, contrastive learning (CL) <d-cite key="SimCLR"></d-cite> is one of the popular self-supervised learning methods. CL aims to maximize the agreement between different natural views of the original data.</p> <p>Let \(f_\theta: \mathcal{X} \rightarrow \mathcal{Z}\) be a feature extractor parameterized by \(\theta\), \(g:\mathcal{Z} \rightarrow \mathcal{V}\) be a projection head that maps representations to the space where the contrastive loss is applied, and \(\tau_i, \tau_j: \mathcal{X} \rightarrow \mathcal{X}\) be two transformation operations randomly sampled from a pre-defined transformation set \(\mathcal{T}\). Given a mini-batch \(B \sim \mathcal{X}^\beta\) consisting of \(\beta\) samples, we denote the augmented minibatch \(B^\prime = \{ \tau_i(x_k), \tau_j(x_k) \mid \forall x_k \in B \}\) consisting of \(2\beta\) samples. We take \(h_\theta(\cdot) = g \circ f_\theta(\cdot)\) and \(x_k^u = \tau_u(x_k)\) for any \(x_k \sim \mathcal{X}\) and \(u \in \{i,j\}\). The contrastive loss between different natural views (i.e., \(x_k^i\) and \(x_k^j\)) is formulated as follows:</p> \[\ell_\mathrm{CL}(x_k^i,x_k^j; \theta)\!=\!-\! \sum\limits_{u \in \{i,j\}} \! \log \frac{e^{\mathrm{sim} \left(h_\theta(x_k^i), h_\theta(x_k^j) \right)/t}}{\sum\limits_{x \in B^\prime \setminus \{x_k^u\}} e^{\mathrm{sim} \left( h_\theta(x_k^u), h_\theta(x) \right)/t}},\] <p>where \(\mathrm{sim}(\cdot,\cdot)\) is the cosine similarity function.</p> <div class="row mt-3"> <div class="col-sm mt-3 mt-md-0"> <figure> <picture> <source class="responsive-img-srcset" media="(max-width: 480px)" srcset="/2024/assets/img/2024-05-07-robust-foundation-model/SCL-480.webp"></source> <source class="responsive-img-srcset" media="(max-width: 800px)" srcset="/2024/assets/img/2024-05-07-robust-foundation-model/SCL-800.webp"></source> <source class="responsive-img-srcset" media="(max-width: 1400px)" srcset="/2024/assets/img/2024-05-07-robust-foundation-model/SCL-1400.webp"></source> <img src="/2024/assets/img/2024-05-07-robust-foundation-model/SCL.png" class="img-fluid" width="auto" height="auto" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"> </picture> </figure> </div> </div> <div class="caption"> Intuitively, CL aims to maximize the agreement between different natural views (<span style="color:blue">the dash blue lines</span>). </div> <p><strong>How to implement CL at the pre-training stage in practice?</strong></p> <details><summary> Click here to see the Pytorch code for calculating contrastive loss. You can copy-paste it to calculate the contrastive loss in convenience. <d-footnote>The code is copied from https://github.com/GodXuxilie/Enhancing_ACL_via_AIR.</d-footnote></summary> <figure class="highlight"><pre><code class="language-python" data-lang="python"><span class="kn">import</span> <span class="n">torch</span>
<span class="kn">import</span> <span class="n">torch.nn</span> <span class="k">as</span> <span class="n">nn</span>
<span class="kn">import</span> <span class="n">torch.nn.functional</span> <span class="k">as</span> <span class="n">F</span>

<span class="k">class</span> <span class="nc">CL</span><span class="p">(</span><span class="n">nn</span><span class="p">.</span><span class="n">Module</span><span class="p">):</span>

    <span class="k">def</span> <span class="nf">__init__</span><span class="p">(</span><span class="n">self</span><span class="p">,</span> <span class="n">normalize</span><span class="o">=</span><span class="bp">True</span><span class="p">,</span> <span class="n">temperature</span><span class="o">=</span><span class="mf">0.5</span><span class="p">):</span>
        <span class="nf">super</span><span class="p">(</span><span class="n">CL</span><span class="p">,</span> <span class="n">self</span><span class="p">).</span><span class="nf">__init__</span><span class="p">()</span>
        <span class="n">self</span><span class="p">.</span><span class="n">normalize</span> <span class="o">=</span> <span class="n">normalize</span>
        <span class="n">self</span><span class="p">.</span><span class="n">temperature</span> <span class="o">=</span> <span class="n">temperature</span>

    <span class="k">def</span> <span class="nf">forward</span><span class="p">(</span><span class="n">self</span><span class="p">,</span> <span class="n">zi</span><span class="p">,</span> <span class="n">zj</span><span class="p">):</span>
        <span class="c1"># zi: the representation of natural view x^i.
</span>        <span class="c1"># zj: the representation of natural view x^j.
</span>
        <span class="n">bs</span> <span class="o">=</span> <span class="n">zi</span><span class="p">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span>
        <span class="n">labels</span> <span class="o">=</span> <span class="n">torch</span><span class="p">.</span><span class="nf">zeros</span><span class="p">((</span><span class="mi">2</span><span class="o">*</span><span class="n">bs</span><span class="p">,)).</span><span class="nf">long</span><span class="p">().</span><span class="nf">to</span><span class="p">(</span><span class="n">zi</span><span class="p">.</span><span class="n">device</span><span class="p">)</span>
        <span class="n">mask</span> <span class="o">=</span> <span class="n">torch</span><span class="p">.</span><span class="nf">ones</span><span class="p">((</span><span class="n">bs</span><span class="p">,</span> <span class="n">bs</span><span class="p">),</span> <span class="n">dtype</span><span class="o">=</span><span class="nb">bool</span><span class="p">).</span><span class="nf">fill_diagonal_</span><span class="p">(</span><span class="mi">0</span><span class="p">)</span>

        <span class="n">zi_norm</span> <span class="o">=</span> <span class="n">F</span><span class="p">.</span><span class="nf">normalize</span><span class="p">(</span><span class="n">zi</span><span class="p">,</span> <span class="n">p</span><span class="o">=</span><span class="mi">2</span><span class="p">,</span> <span class="n">dim</span><span class="o">=-</span><span class="mi">1</span><span class="p">)</span> <span class="k">if</span> <span class="n">self</span><span class="p">.</span><span class="n">normalize</span> <span class="k">else</span> <span class="n">zi</span>
        <span class="n">zj_norm</span> <span class="o">=</span> <span class="n">F</span><span class="p">.</span><span class="nf">normalize</span><span class="p">(</span><span class="n">zj</span><span class="p">,</span> <span class="n">p</span><span class="o">=</span><span class="mi">2</span><span class="p">,</span> <span class="n">dim</span><span class="o">=-</span><span class="mi">1</span><span class="p">)</span> <span class="k">if</span> <span class="n">self</span><span class="p">.</span><span class="n">normalize</span> <span class="k">else</span> <span class="n">zj</span>

        <span class="c1">### Contrastive Loss ###
</span>        <span class="n">logits_ii</span> <span class="o">=</span> <span class="n">torch</span><span class="p">.</span><span class="nf">mm</span><span class="p">(</span><span class="n">zi_norm</span><span class="p">,</span> <span class="n">zi_norm</span><span class="p">.</span><span class="nf">t</span><span class="p">())</span> <span class="o">/</span> <span class="n">self</span><span class="p">.</span><span class="n">temperature</span>
        <span class="n">logits_ij</span> <span class="o">=</span> <span class="n">torch</span><span class="p">.</span><span class="nf">mm</span><span class="p">(</span><span class="n">zi_norm</span><span class="p">,</span> <span class="n">zj_norm</span><span class="p">.</span><span class="nf">t</span><span class="p">())</span> <span class="o">/</span> <span class="n">self</span><span class="p">.</span><span class="n">temperature</span>
        <span class="n">logits_ji</span> <span class="o">=</span> <span class="n">torch</span><span class="p">.</span><span class="nf">mm</span><span class="p">(</span><span class="n">zj_norm</span><span class="p">,</span> <span class="n">zi_norm</span><span class="p">.</span><span class="nf">t</span><span class="p">())</span> <span class="o">/</span> <span class="n">self</span><span class="p">.</span><span class="n">temperature</span>
        <span class="n">logits_jj</span> <span class="o">=</span> <span class="n">torch</span><span class="p">.</span><span class="nf">mm</span><span class="p">(</span><span class="n">zj_norm</span><span class="p">,</span> <span class="n">zj_norm</span><span class="p">.</span><span class="nf">t</span><span class="p">())</span> <span class="o">/</span> <span class="n">self</span><span class="p">.</span><span class="n">temperature</span>

        <span class="n">logits_ij_pos</span> <span class="o">=</span> <span class="n">logits_ij</span><span class="p">[</span><span class="n">torch</span><span class="p">.</span><span class="nf">logical_not</span><span class="p">(</span><span class="n">mask</span><span class="p">)]</span>                                          
        <span class="n">logits_ji_pos</span> <span class="o">=</span> <span class="n">logits_ji</span><span class="p">[</span><span class="n">torch</span><span class="p">.</span><span class="nf">logical_not</span><span class="p">(</span><span class="n">mask</span><span class="p">)]</span>                                          
        <span class="n">logits_ii_neg</span> <span class="o">=</span> <span class="n">logits_ii</span><span class="p">[</span><span class="n">mask</span><span class="p">].</span><span class="nf">reshape</span><span class="p">(</span><span class="n">bs</span><span class="p">,</span> <span class="o">-</span><span class="mi">1</span><span class="p">)</span>                                            
        <span class="n">logits_ij_neg</span> <span class="o">=</span> <span class="n">logits_ij</span><span class="p">[</span><span class="n">mask</span><span class="p">].</span><span class="nf">reshape</span><span class="p">(</span><span class="n">bs</span><span class="p">,</span> <span class="o">-</span><span class="mi">1</span><span class="p">)</span>                                             
        <span class="n">logits_ji_neg</span> <span class="o">=</span> <span class="n">logits_ji</span><span class="p">[</span><span class="n">mask</span><span class="p">].</span><span class="nf">reshape</span><span class="p">(</span><span class="n">bs</span><span class="p">,</span> <span class="o">-</span><span class="mi">1</span><span class="p">)</span>                                             
        <span class="n">logits_jj_neg</span> <span class="o">=</span> <span class="n">logits_jj</span><span class="p">[</span><span class="n">mask</span><span class="p">].</span><span class="nf">reshape</span><span class="p">(</span><span class="n">bs</span><span class="p">,</span> <span class="o">-</span><span class="mi">1</span><span class="p">)</span>                                             

        <span class="n">pos</span> <span class="o">=</span> <span class="n">torch</span><span class="p">.</span><span class="nf">cat</span><span class="p">((</span><span class="n">logits_ij_pos</span><span class="p">,</span> <span class="n">logits_ji_pos</span><span class="p">),</span> <span class="n">dim</span><span class="o">=</span><span class="mi">0</span><span class="p">).</span><span class="nf">unsqueeze</span><span class="p">(</span><span class="mi">1</span><span class="p">)</span>                         
        <span class="n">neg_i</span> <span class="o">=</span> <span class="n">torch</span><span class="p">.</span><span class="nf">cat</span><span class="p">((</span><span class="n">logits_ii_neg</span><span class="p">,</span> <span class="n">logits_ij_neg</span><span class="p">),</span> <span class="n">dim</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>                                    
        <span class="n">neg_j</span> <span class="o">=</span> <span class="n">torch</span><span class="p">.</span><span class="nf">cat</span><span class="p">((</span><span class="n">logits_ji_neg</span><span class="p">,</span> <span class="n">logits_jj_neg</span><span class="p">),</span> <span class="n">dim</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>                                    
        <span class="n">neg</span> <span class="o">=</span> <span class="n">torch</span><span class="p">.</span><span class="nf">cat</span><span class="p">((</span><span class="n">neg_i</span><span class="p">,</span> <span class="n">neg_j</span><span class="p">),</span> <span class="n">dim</span><span class="o">=</span><span class="mi">0</span><span class="p">)</span>                                                      

        <span class="n">logits</span> <span class="o">=</span> <span class="n">torch</span><span class="p">.</span><span class="nf">cat</span><span class="p">((</span><span class="n">pos</span><span class="p">,</span> <span class="n">neg</span><span class="p">),</span> <span class="n">dim</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>                                                       
        <span class="n">nat_contrastive_loss</span> <span class="o">=</span> <span class="n">F</span><span class="p">.</span><span class="nf">cross_entropy</span><span class="p">(</span><span class="n">logits</span><span class="p">,</span> <span class="n">labels</span><span class="p">)</span>
        <span class="k">return</span> <span class="n">nat_contrastive_loss</span></code></pre></figure> </details> <p>Besides, you can use the following script to conduct self-supervised pre-training via CL using ResNet-18 on CIFAR-10:</p> <figure class="highlight"><pre><code class="language-bash" data-lang="bash"><span class="c"># Pre-training stage via CL</span>
git clone https://github.com/GodXuxilie/Enhancing_ACL_via_AIR.git
<span class="nb">cd </span>Enhancing_ACL_via_AIR
<span class="nv">PRE_TRAIN_DIR</span><span class="o">=</span>CL_ResNet18_cifar10
python pretraining.py <span class="nv">$PRE_TRAIN_DIR</span> <span class="nt">--dataset</span> cifar10 <span class="se">\</span>
                                     <span class="nt">--model</span> r18 <span class="se">\</span>
                                     <span class="nt">--pgd_iter</span> 0  <span class="nt">--lambda1</span> 0 <span class="nt">--lambda2</span> 0</code></pre></figure> <h2 id="robust-foundation-models">Robust Foundation Models</h2> <p>Existing work <d-cite key="pre"></d-cite> has shown that there exist adversarial attacks that can fool the foundation representations to output incorrect predictions by adding imperceptible adversarial perturbations to the original inputs in downstream tasks. The existence of adversarial attacks <d-cite key="FGSM"></d-cite> necessitates the development of robust foundation models in safety-critical downstream tasks.</p> <div class="row mt-3"> <div class="col-sm mt-3 mt-md-0"> <figure> <picture> <source class="responsive-img-srcset" media="(max-width: 480px)" srcset="/2024/assets/img/2024-05-07-robust-foundation-model/adv_attack-480.webp"></source> <source class="responsive-img-srcset" media="(max-width: 800px)" srcset="/2024/assets/img/2024-05-07-robust-foundation-model/adv_attack-800.webp"></source> <source class="responsive-img-srcset" media="(max-width: 1400px)" srcset="/2024/assets/img/2024-05-07-robust-foundation-model/adv_attack-1400.webp"></source> <img src="/2024/assets/img/2024-05-07-robust-foundation-model/adv_attack.png" class="img-fluid" width="auto" height="auto" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"> </picture> </figure> </div> </div> <div class="caption"> The foundation representation is vulnerable to adversarial attacks, which wrongly predicts a car as 'NOT a car'. </div> <p>Robust foundation models are pre-trained on large-scale datasets via robust self-supervised learning methods. Robust foundation models have the following two critical properties:</p> <ul> <li>Robust foundation representations is generalizable to downstream tasks;</li> <li>Fine-tuned robust foundation representations is adversarially robust against adversarial attacks in downstream tasks.</li> </ul> <div class="row mt-3"> <div class="col-sm mt-3 mt-md-0"> <figure> <picture> <source class="responsive-img-srcset" media="(max-width: 480px)" srcset="/2024/assets/img/2024-05-07-robust-foundation-model/robust_foundation_models-480.webp"></source> <source class="responsive-img-srcset" media="(max-width: 800px)" srcset="/2024/assets/img/2024-05-07-robust-foundation-model/robust_foundation_models-800.webp"></source> <source class="responsive-img-srcset" media="(max-width: 1400px)" srcset="/2024/assets/img/2024-05-07-robust-foundation-model/robust_foundation_models-1400.webp"></source> <img src="/2024/assets/img/2024-05-07-robust-foundation-model/robust_foundation_models.png" class="img-fluid" width="auto" height="auto" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"> </picture> </figure> </div> </div> <h3 id="adversarial-contrastive-learning-acl">Adversarial Contrastive Learning (ACL)</h3> <p>To learn robust foundation representations, adversarial contrastive learning (ACL) <d-cite key="ACL"></d-cite> is one of the most popular and effective robust self-supervised learning methods. ACL incorporates CL with adversarial data to build a robust foundation model without requiring costly annotations. ACL aims to maximize the agreement between different natural views as well as the agreement between different adversarial views. The adversarial contrastive loss given a data point \(x_k \in \mathcal{X}\) is formulated as follows:</p> \[\ell_\mathrm{ACL}(x_k;\theta) = (1 + \omega) \cdot \ell_\mathrm{CL}(\tilde{x}_{k}^i, \tilde{x}_{k}^j; \theta) + (1 - \omega) \cdot \ell_\mathrm{CL}(x_k^i, x_k^j; \theta),\] <p>where adversarial views are formulated as follows:</p> \[\tilde{x}_{k}^i, \tilde{x}_{k}^j = \mathop{\arg\max}_{ {\Large \tilde{x}_{k}^i \in \mathcal{B}_\epsilon[x_k^i]} \atop {\Large \tilde{x}_{k}^j \in \mathcal{B}_\epsilon[x_k^j]} } \ell_\mathrm{CL}(\tilde{x}_{k}^i, \tilde{x}_{k}^j; \theta).\] <p>Note that \(\omega \in [0,1]\) is a scalar and \(\mathcal{B}_\epsilon[x]\) is a constraint that ensures the adversarial data \(\tilde{x}\) is in the \(\epsilon\)-ball around data \(x\).</p> <div class="row mt-3"> <div class="col-sm mt-3 mt-md-0"> <figure> <picture> <source class="responsive-img-srcset" media="(max-width: 480px)" srcset="/2024/assets/img/2024-05-07-robust-foundation-model/ACL-480.webp"></source> <source class="responsive-img-srcset" media="(max-width: 800px)" srcset="/2024/assets/img/2024-05-07-robust-foundation-model/ACL-800.webp"></source> <source class="responsive-img-srcset" media="(max-width: 1400px)" srcset="/2024/assets/img/2024-05-07-robust-foundation-model/ACL-1400.webp"></source> <img src="/2024/assets/img/2024-05-07-robust-foundation-model/ACL.png" class="img-fluid" width="auto" height="auto" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"> </picture> </figure> </div> </div> <div class="caption"> Intuitively, ACL aims to maximize the agreement between different natural view (<span style="color:blue">the dash blue lines</span>) and the agreement between different adversarial views (<span style="color:red">the dash red lines</span>). </div> <p>Here is the generation procedure of adversarial data via Projected Gradient Descent (PGD) <d-cite key="PGD"></d-cite>. Given an initial positive pair \((x_k^{i,(0)}, x_k^{j,(0)})\), PGD step \(T \in \mathbb{N}\), step size \(\rho &gt; 0\), and adversarial budget \(\epsilon \geq 0\), PGD iteratively updates the pair of data from \(t=0\) to \(T-1\) as follows:</p> \[x_k^{i,(t+1)} \! = \! \Pi_{\mathcal{B}_\epsilon[x_k^{i,(0)}]} \big( x_k^{i,(t)} +\rho \cdot \mathrm{sign} (\nabla_{x_k^{i,(t)}} \ell_\mathrm{CL}(x_k^{i,(t)}, x_k^{j,(t)}) \big ),\] \[x_k^{j,(t+1)} \! = \! \Pi_{\mathcal{B}_\epsilon[x_k^{j,(0)}]} \big( x_k^{j,(t)} +\rho \cdot \mathrm{sign} (\nabla_{x_k^{j,(t)}} \ell_\mathrm{CL}(x_k^{i,(t)}, x_k^{j,(t)}) \big ),\] <p>where \(\Pi_{\mathcal{B}_\epsilon[x]}\) projects the data into the \(\epsilon\)-ball around the initial point \(x\). Generating adversarial data requires \(T\) iterations of forwarding and back-propagations, which makes the training procedure extremely slow.</p> <div class="row mt-3"> <div class="col-sm mt-3 mt-md-0"> <figure> <picture> <source class="responsive-img-srcset" media="(max-width: 480px)" srcset="/2024/assets/img/2024-05-07-robust-foundation-model/pgd_step.gif-480.webp"></source> <source class="responsive-img-srcset" media="(max-width: 800px)" srcset="/2024/assets/img/2024-05-07-robust-foundation-model/pgd_step.gif-800.webp"></source> <source class="responsive-img-srcset" media="(max-width: 1400px)" srcset="/2024/assets/img/2024-05-07-robust-foundation-model/pgd_step.gif-1400.webp"></source> <img src="/2024/assets/img/2024-05-07-robust-foundation-model/pgd_step.gif" class="img-fluid" width="auto" height="auto" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"> </picture> </figure> </div> </div> <div class="caption"> The generation procedure of adversarial data in ACL. The adversarial data $\tilde{x}_k^i$ and $\tilde{x}_k^j$ are updated from the low-loss region to the high-loss region step by step according to the loss gradient. </div> <p>At each epoch, ACL conducts steps (1) and (2) alternatively:</p> <ul> <li> <p>Step (1): generating adversarial data (i.e., \(\tilde{x}_k^i\) and \(\tilde{x}_k^j\)) via PGD;</p> </li> <li> <p>Step (2): updating model parameters via minimizing adversarial contrastive loss to maximize agreements on the adversarial data and natural data.</p> </li> </ul> <p><strong>How to implement ACL at the pre-training stage in practice?</strong></p> <details><summary>Click here to see the Pytorch code for calculating adversarial contrastive loss. You can copy-paste it to calculate the adversarial contrastive loss in convenience. <d-footnote>The code is copied from https://github.com/GodXuxilie/Enhancing_ACL_via_AIR.</d-footnote></summary> <figure class="highlight"><pre><code class="language-python" data-lang="python"><span class="kn">import</span> <span class="n">torch</span>
<span class="kn">import</span> <span class="n">torch.nn</span> <span class="k">as</span> <span class="n">nn</span>
<span class="kn">import</span> <span class="n">torch.nn.functional</span> <span class="k">as</span> <span class="n">F</span>

<span class="k">class</span> <span class="nc">ACL</span><span class="p">(</span><span class="n">nn</span><span class="p">.</span><span class="n">Module</span><span class="p">):</span>

    <span class="k">def</span> <span class="nf">__init__</span><span class="p">(</span><span class="n">self</span><span class="p">,</span> <span class="n">normalize</span><span class="o">=</span><span class="bp">True</span><span class="p">,</span> <span class="n">temperature</span><span class="o">=</span><span class="mf">0.5</span><span class="p">):</span>
        <span class="nf">super</span><span class="p">(</span><span class="n">ACL</span><span class="p">,</span> <span class="n">self</span><span class="p">).</span><span class="nf">__init__</span><span class="p">()</span>
        <span class="n">self</span><span class="p">.</span><span class="n">normalize</span> <span class="o">=</span> <span class="n">normalize</span>
        <span class="n">self</span><span class="p">.</span><span class="n">temperature</span> <span class="o">=</span> <span class="n">temperature</span>

    <span class="k">def</span> <span class="nf">forward</span><span class="p">(</span><span class="n">self</span><span class="p">,</span> <span class="n">zi</span><span class="p">,</span> <span class="n">zj</span><span class="p">,</span> <span class="n">zi_adv</span><span class="p">,</span> <span class="n">zj_adv</span><span class="p">,</span> <span class="n">weight</span><span class="o">=</span><span class="mf">0.5</span><span class="p">):</span>
        <span class="c1"># zi: the representation of natural view x^i.
</span>        <span class="c1"># zj: the representation of natural view x^j.
</span>        <span class="c1"># zi_adv: the representation of adversarial view \tilde{x}^i.
</span>        <span class="c1"># zj_adv: the representation of adversarial view \tilde{x}^j.
</span>
        <span class="n">bs</span> <span class="o">=</span> <span class="n">zi</span><span class="p">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span>
        <span class="n">labels</span> <span class="o">=</span> <span class="n">torch</span><span class="p">.</span><span class="nf">zeros</span><span class="p">((</span><span class="mi">2</span><span class="o">*</span><span class="n">bs</span><span class="p">,)).</span><span class="nf">long</span><span class="p">().</span><span class="nf">to</span><span class="p">(</span><span class="n">zi</span><span class="p">.</span><span class="n">device</span><span class="p">)</span>
        <span class="n">mask</span> <span class="o">=</span> <span class="n">torch</span><span class="p">.</span><span class="nf">ones</span><span class="p">((</span><span class="n">bs</span><span class="p">,</span> <span class="n">bs</span><span class="p">),</span> <span class="n">dtype</span><span class="o">=</span><span class="nb">bool</span><span class="p">).</span><span class="nf">fill_diagonal_</span><span class="p">(</span><span class="mi">0</span><span class="p">)</span>

        <span class="n">zi_norm</span> <span class="o">=</span> <span class="n">F</span><span class="p">.</span><span class="nf">normalize</span><span class="p">(</span><span class="n">zi</span><span class="p">,</span> <span class="n">p</span><span class="o">=</span><span class="mi">2</span><span class="p">,</span> <span class="n">dim</span><span class="o">=-</span><span class="mi">1</span><span class="p">)</span> <span class="k">if</span> <span class="n">self</span><span class="p">.</span><span class="n">normalize</span> <span class="k">else</span> <span class="n">zi</span>
        <span class="n">zj_norm</span> <span class="o">=</span> <span class="n">F</span><span class="p">.</span><span class="nf">normalize</span><span class="p">(</span><span class="n">zj</span><span class="p">,</span> <span class="n">p</span><span class="o">=</span><span class="mi">2</span><span class="p">,</span> <span class="n">dim</span><span class="o">=-</span><span class="mi">1</span><span class="p">)</span> <span class="k">if</span> <span class="n">self</span><span class="p">.</span><span class="n">normalize</span> <span class="k">else</span> <span class="n">zj</span>
        <span class="n">zi_adv_norm</span> <span class="o">=</span> <span class="n">F</span><span class="p">.</span><span class="nf">normalize</span><span class="p">(</span><span class="n">zi_adv</span><span class="p">,</span> <span class="n">p</span><span class="o">=</span><span class="mi">2</span><span class="p">,</span> <span class="n">dim</span><span class="o">=-</span><span class="mi">1</span><span class="p">)</span> <span class="k">if</span> <span class="n">self</span><span class="p">.</span><span class="n">normalize</span> <span class="k">else</span> <span class="n">zi_adv</span>
        <span class="n">zj_adv_norm</span> <span class="o">=</span> <span class="n">F</span><span class="p">.</span><span class="nf">normalize</span><span class="p">(</span><span class="n">zj_adv</span><span class="p">,</span> <span class="n">p</span><span class="o">=</span><span class="mi">2</span><span class="p">,</span> <span class="n">dim</span><span class="o">=-</span><span class="mi">1</span><span class="p">)</span> <span class="n">i</span> <span class="k">if</span> <span class="n">self</span><span class="p">.</span><span class="n">normalize</span> <span class="k">else</span> <span class="n">zj_adv</span>
        
        <span class="c1">### Adversarial Contrastive Loss ###
</span>
        <span class="n">logits_ii</span> <span class="o">=</span> <span class="n">torch</span><span class="p">.</span><span class="nf">mm</span><span class="p">(</span><span class="n">zi_norm</span><span class="p">,</span> <span class="n">zi_norm</span><span class="p">.</span><span class="nf">t</span><span class="p">())</span> <span class="o">/</span> <span class="n">self</span><span class="p">.</span><span class="n">temperature</span>
        <span class="n">logits_ij</span> <span class="o">=</span> <span class="n">torch</span><span class="p">.</span><span class="nf">mm</span><span class="p">(</span><span class="n">zi_norm</span><span class="p">,</span> <span class="n">zj_norm</span><span class="p">.</span><span class="nf">t</span><span class="p">())</span> <span class="o">/</span> <span class="n">self</span><span class="p">.</span><span class="n">temperature</span>
        <span class="n">logits_ji</span> <span class="o">=</span> <span class="n">torch</span><span class="p">.</span><span class="nf">mm</span><span class="p">(</span><span class="n">zj_norm</span><span class="p">,</span> <span class="n">zi_norm</span><span class="p">.</span><span class="nf">t</span><span class="p">())</span> <span class="o">/</span> <span class="n">self</span><span class="p">.</span><span class="n">temperature</span>
        <span class="n">logits_jj</span> <span class="o">=</span> <span class="n">torch</span><span class="p">.</span><span class="nf">mm</span><span class="p">(</span><span class="n">zj_norm</span><span class="p">,</span> <span class="n">zj_norm</span><span class="p">.</span><span class="nf">t</span><span class="p">())</span> <span class="o">/</span> <span class="n">self</span><span class="p">.</span><span class="n">temperature</span>

        <span class="n">logits_ij_pos</span> <span class="o">=</span> <span class="n">logits_ij</span><span class="p">[</span><span class="n">torch</span><span class="p">.</span><span class="nf">logical_not</span><span class="p">(</span><span class="n">mask</span><span class="p">)]</span>                                          
        <span class="n">logits_ji_pos</span> <span class="o">=</span> <span class="n">logits_ji</span><span class="p">[</span><span class="n">torch</span><span class="p">.</span><span class="nf">logical_not</span><span class="p">(</span><span class="n">mask</span><span class="p">)]</span>                                          
        <span class="n">logits_ii_neg</span> <span class="o">=</span> <span class="n">logits_ii</span><span class="p">[</span><span class="n">mask</span><span class="p">].</span><span class="nf">reshape</span><span class="p">(</span><span class="n">bs</span><span class="p">,</span> <span class="o">-</span><span class="mi">1</span><span class="p">)</span>                                            
        <span class="n">logits_ij_neg</span> <span class="o">=</span> <span class="n">logits_ij</span><span class="p">[</span><span class="n">mask</span><span class="p">].</span><span class="nf">reshape</span><span class="p">(</span><span class="n">bs</span><span class="p">,</span> <span class="o">-</span><span class="mi">1</span><span class="p">)</span>                                             
        <span class="n">logits_ji_neg</span> <span class="o">=</span> <span class="n">logits_ji</span><span class="p">[</span><span class="n">mask</span><span class="p">].</span><span class="nf">reshape</span><span class="p">(</span><span class="n">bs</span><span class="p">,</span> <span class="o">-</span><span class="mi">1</span><span class="p">)</span>                                             
        <span class="n">logits_jj_neg</span> <span class="o">=</span> <span class="n">logits_jj</span><span class="p">[</span><span class="n">mask</span><span class="p">].</span><span class="nf">reshape</span><span class="p">(</span><span class="n">bs</span><span class="p">,</span> <span class="o">-</span><span class="mi">1</span><span class="p">)</span>                                             

        <span class="n">pos</span> <span class="o">=</span> <span class="n">torch</span><span class="p">.</span><span class="nf">cat</span><span class="p">((</span><span class="n">logits_ij_pos</span><span class="p">,</span> <span class="n">logits_ji_pos</span><span class="p">),</span> <span class="n">dim</span><span class="o">=</span><span class="mi">0</span><span class="p">).</span><span class="nf">unsqueeze</span><span class="p">(</span><span class="mi">1</span><span class="p">)</span>                         
        <span class="n">neg_i</span> <span class="o">=</span> <span class="n">torch</span><span class="p">.</span><span class="nf">cat</span><span class="p">((</span><span class="n">logits_ii_neg</span><span class="p">,</span> <span class="n">logits_ij_neg</span><span class="p">),</span> <span class="n">dim</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>                                    
        <span class="n">neg_j</span> <span class="o">=</span> <span class="n">torch</span><span class="p">.</span><span class="nf">cat</span><span class="p">((</span><span class="n">logits_ji_neg</span><span class="p">,</span> <span class="n">logits_jj_neg</span><span class="p">),</span> <span class="n">dim</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>                                    
        <span class="n">neg</span> <span class="o">=</span> <span class="n">torch</span><span class="p">.</span><span class="nf">cat</span><span class="p">((</span><span class="n">neg_i</span><span class="p">,</span> <span class="n">neg_j</span><span class="p">),</span> <span class="n">dim</span><span class="o">=</span><span class="mi">0</span><span class="p">)</span>                                                      

        <span class="n">logits</span> <span class="o">=</span> <span class="n">torch</span><span class="p">.</span><span class="nf">cat</span><span class="p">((</span><span class="n">pos</span><span class="p">,</span> <span class="n">neg</span><span class="p">),</span> <span class="n">dim</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>                                                       
        <span class="n">nat_contrastive_loss</span> <span class="o">=</span> <span class="n">F</span><span class="p">.</span><span class="nf">cross_entropy</span><span class="p">(</span><span class="n">logits</span><span class="p">,</span> <span class="n">labels</span><span class="p">)</span>

        <span class="n">logits_ii_adv</span> <span class="o">=</span> <span class="n">torch</span><span class="p">.</span><span class="nf">mm</span><span class="p">(</span><span class="n">zi_adv_norm</span><span class="p">,</span> <span class="n">zi_adv_norm</span><span class="p">.</span><span class="nf">t</span><span class="p">())</span> <span class="o">/</span> <span class="n">self</span><span class="p">.</span><span class="n">temperature</span>
        <span class="n">logits_ij_adv</span> <span class="o">=</span> <span class="n">torch</span><span class="p">.</span><span class="nf">mm</span><span class="p">(</span><span class="n">zi_adv_norm</span><span class="p">,</span> <span class="n">zj_adv_norm</span><span class="p">.</span><span class="nf">t</span><span class="p">())</span> <span class="o">/</span> <span class="n">self</span><span class="p">.</span><span class="n">temperature</span>
        <span class="n">logits_ji_adv</span> <span class="o">=</span> <span class="n">torch</span><span class="p">.</span><span class="nf">mm</span><span class="p">(</span><span class="n">zj_adv_norm</span><span class="p">,</span> <span class="n">zi_adv_norm</span><span class="p">.</span><span class="nf">t</span><span class="p">())</span> <span class="o">/</span> <span class="n">self</span><span class="p">.</span><span class="n">temperature</span>
        <span class="n">logits_jj_adv</span> <span class="o">=</span> <span class="n">torch</span><span class="p">.</span><span class="nf">mm</span><span class="p">(</span><span class="n">zj_adv_norm</span><span class="p">,</span> <span class="n">zj_adv_norm</span><span class="p">.</span><span class="nf">t</span><span class="p">())</span> <span class="o">/</span> <span class="n">self</span><span class="p">.</span><span class="n">temperature</span>

        <span class="n">logits_ij_pos_adv</span> <span class="o">=</span> <span class="n">logits_ij_adv</span><span class="p">[</span><span class="n">torch</span><span class="p">.</span><span class="nf">logical_not</span><span class="p">(</span><span class="n">mask</span><span class="p">)]</span>                                         
        <span class="n">logits_ji_pos_adv</span> <span class="o">=</span> <span class="n">logits_ji_adv</span><span class="p">[</span><span class="n">torch</span><span class="p">.</span><span class="nf">logical_not</span><span class="p">(</span><span class="n">mask</span><span class="p">)]</span>                                          
        <span class="n">logits_ii_neg_adv</span> <span class="o">=</span> <span class="n">logits_ii_adv</span><span class="p">[</span><span class="n">mask</span><span class="p">].</span><span class="nf">reshape</span><span class="p">(</span><span class="n">bs</span><span class="p">,</span> <span class="o">-</span><span class="mi">1</span><span class="p">)</span>                                            
        <span class="n">logits_ij_neg_adv</span> <span class="o">=</span> <span class="n">logits_ij_adv</span><span class="p">[</span><span class="n">mask</span><span class="p">].</span><span class="nf">reshape</span><span class="p">(</span><span class="n">bs</span><span class="p">,</span> <span class="o">-</span><span class="mi">1</span><span class="p">)</span>                                             
        <span class="n">logits_ji_neg_adv</span> <span class="o">=</span> <span class="n">logits_ji_adv</span><span class="p">[</span><span class="n">mask</span><span class="p">].</span><span class="nf">reshape</span><span class="p">(</span><span class="n">bs</span><span class="p">,</span> <span class="o">-</span><span class="mi">1</span><span class="p">)</span>                                             
        <span class="n">logits_jj_neg_adv</span> <span class="o">=</span> <span class="n">logits_jj_adv</span><span class="p">[</span><span class="n">mask</span><span class="p">].</span><span class="nf">reshape</span><span class="p">(</span><span class="n">bs</span><span class="p">,</span> <span class="o">-</span><span class="mi">1</span><span class="p">)</span>                                             

        <span class="n">pos_adv</span> <span class="o">=</span> <span class="n">torch</span><span class="p">.</span><span class="nf">cat</span><span class="p">((</span><span class="n">logits_ij_pos_adv</span><span class="p">,</span> <span class="n">logits_ji_pos_adv</span><span class="p">),</span> <span class="n">dim</span><span class="o">=</span><span class="mi">0</span><span class="p">).</span><span class="nf">unsqueeze</span><span class="p">(</span><span class="mi">1</span><span class="p">)</span>                         
        <span class="n">neg_i_adv</span> <span class="o">=</span> <span class="n">torch</span><span class="p">.</span><span class="nf">cat</span><span class="p">((</span><span class="n">logits_ii_neg_adv</span><span class="p">,</span> <span class="n">logits_ij_neg_adv</span><span class="p">),</span> <span class="n">dim</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>                                    
        <span class="n">neg_j_adv</span> <span class="o">=</span> <span class="n">torch</span><span class="p">.</span><span class="nf">cat</span><span class="p">((</span><span class="n">logits_ji_neg_adv</span><span class="p">,</span> <span class="n">logits_jj_neg_adv</span><span class="p">),</span> <span class="n">dim</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>                                    
        <span class="n">neg_adv</span> <span class="o">=</span> <span class="n">torch</span><span class="p">.</span><span class="nf">cat</span><span class="p">((</span><span class="n">neg_i_adv</span><span class="p">,</span> <span class="n">neg_j_adv</span><span class="p">),</span> <span class="n">dim</span><span class="o">=</span><span class="mi">0</span><span class="p">)</span>                                                      

        <span class="n">logits_adv</span> <span class="o">=</span> <span class="n">torch</span><span class="p">.</span><span class="nf">cat</span><span class="p">((</span><span class="n">pos_adv</span><span class="p">,</span> <span class="n">neg_adv</span><span class="p">),</span> <span class="n">dim</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>                                                       
        <span class="n">adv_contrastive_loss</span> <span class="o">=</span> <span class="n">F</span><span class="p">.</span><span class="nf">cross_entropy</span><span class="p">(</span><span class="n">logits_adv</span><span class="p">,</span> <span class="n">labels</span><span class="p">)</span>

        <span class="nf">return </span><span class="p">(</span><span class="mi">1</span> <span class="o">-</span> <span class="n">weight</span><span class="p">)</span> <span class="o">*</span> <span class="n">nat_contrastive_loss</span> <span class="o">+</span> <span class="p">(</span><span class="mi">1</span> <span class="o">+</span> <span class="n">weight</span><span class="p">)</span> <span class="o">*</span> <span class="n">adv_contrastive_loss</span></code></pre></figure> </details> <p>Besides, you can use the following script to conduct robust self-supervised pre-training via ACL using ResNet-18 on CIFAR-10:</p> <figure class="highlight"><pre><code class="language-bash" data-lang="bash"><span class="c"># Pre-training stage via ACL</span>
git clone https://github.com/GodXuxilie/Enhancing_ACL_via_AIR.git
<span class="nb">cd </span>Enhancing_ACL_via_AIR
<span class="nv">PRE_TRAIN_DIR</span><span class="o">=</span>ACL_ResNet18_cifar10
python pretraining.py <span class="nv">$PRE_TRAIN_DIR</span> <span class="nt">--dataset</span> cifar10 <span class="se">\</span>
                                     <span class="nt">--model</span> r18 <span class="se">\</span>
                                     <span class="nt">--DynAug</span> <span class="nt">--lambda1</span> 0 <span class="nt">--lambda2</span> 0</code></pre></figure> <p><strong>How to utilize robust foundation representations via fine-tuning in downstream tasks?</strong></p> <p>At the fine-tuning stage, a classifier is randomly initialized and appended to the pre-trained feature extractor for solving the classification tasks. There are three types of fine-tuning modes:</p> <ol> <li>Standard linear fine-tuning (SLF): only standardly fine-tuning the classifier while freezing the feature extractor.</li> <li>Adversarial linear fine-tuning (ALF): only adversarially fine-tuning the classifier while freezing the feature extractor.</li> <li>Adversarial full fine-tuning (AFF): adversarially fine-tuning both the feature extractor and the classifier.</li> </ol> <p>You can use the following script to transfer an adversarially pre-trained ResNet-18 on CIFAR-10 to a downstream task CIFAR-100 via fine-tuning:</p> <figure class="highlight"><pre><code class="language-bash" data-lang="bash"><span class="c"># Fine-tuning stage</span>
<span class="nb">cd </span>Enhancing_ACL_via_AIR
<span class="nv">PRE_TRAIN_DIR</span><span class="o">=</span>ACL_ResNet18_cifar10
<span class="nv">FINETUNE_DIR</span><span class="o">=</span>ACL_ResNet18_cifar10_cifar100
<span class="nv">MODE</span><span class="o">=</span>SLF/ALF/AFF/ALL
python finetuning.py <span class="nt">--mode</span> <span class="nv">$MODE</span> <span class="se">\</span>
                     <span class="nt">--experiment</span> <span class="nv">$FINETUNE_DIR</span> <span class="se">\</span>
                     <span class="nt">--checkpoint</span> ./checkpoints/<span class="nv">$PRE_TRAIN_DIR</span>/model.pt <span class="se">\</span>
                     <span class="nt">--dataset</span> cifar100 <span class="se">\</span>
                     <span class="nt">--model</span> r18 <span class="se">\</span>
                     <span class="nt">--eval-AA</span> <span class="nt">--eval-OOD</span> <span class="nt">--pretraining</span> DynACL</code></pre></figure> <p>Note that <code class="language-plaintext highlighter-rouge">MODE=ALL</code> refers to that the <code class="language-plaintext highlighter-rouge">finetuning.py</code> sequentially conducts fine-tuning of all three modes (i.e., SLF, ALF, and AFF) and outputs the result via each fine-tuning mode in the log file <code class="language-plaintext highlighter-rouge">$FINETUNE_DIR/results/log.txt</code>.</p> <h2 id="enhancing-acl-via-adversarial-invariant-regularization-air">Enhancing ACL via Adversarial Invariant Regularization (AIR)</h2> <p>Here, we introduce the NeurIPS 2023 paper <d-cite key="AIR"></d-cite> which proposes Adversarial Invariant Regularization (AIR) that regulates both standard and robust representations to be style-independent based on a causal theoretical framework. Empirically, AIR yields state-of-the-art performance in terms of robustness against adversarial attacks and common corruption as well as the standard generalization in downstream tasks.</p> <h3 id="causal-view-of-acl">Causal View of ACL</h3> <p>AIR <d-cite key="AIR"></d-cite> first introduces the causal graph of the ACL as shown in the following figure.</p> <div class="row mt-3"> <div class="col-sm mt-3 mt-md-0"> <figure> <picture> <source class="responsive-img-srcset" media="(max-width: 480px)" srcset="/2024/assets/img/2024-05-07-robust-foundation-model/causal_graph-480.webp"></source> <source class="responsive-img-srcset" media="(max-width: 800px)" srcset="/2024/assets/img/2024-05-07-robust-foundation-model/causal_graph-800.webp"></source> <source class="responsive-img-srcset" media="(max-width: 1400px)" srcset="/2024/assets/img/2024-05-07-robust-foundation-model/causal_graph-1400.webp"></source> <img src="/2024/assets/img/2024-05-07-robust-foundation-model/causal_graph.png" class="img-fluid" width="auto" height="auto" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"> </picture> </figure> </div> </div> <div class="caption"> The causal graph of the ACL. </div> <p>During <strong>the data generation procedure</strong>:</p> <ul> <li>\(c\) is the content variable, which can be regarded as the original data in the datasets.</li> <li>\(s\) is the style factor, which can regarded as the data transformation functions that can modify the content while maintaining the semantic meaning of the content. Note that factors \(c\) and \(s\) are independent.</li> <li>\(x\) is the natural data, which is decided by the content factor \(c\) and the style factor \(s\).</li> <li>\(y_t \in \{ y_i \}_{i=1}^{T}\) is the label from an unknown downstream task. Note that \(y_t\) is only decided by the content factor \(c\).</li> <li>\(y^R\) is the proxy label, which is a refinement of $y_t$. \(y^R\) is used for self-supervised learning without labels. As illustrated in the following figure, the label <code class="language-plaintext highlighter-rouge">dog</code> is refined into proxy labels <code class="language-plaintext highlighter-rouge">golden Retriever with yellow hair</code> and <code class="language-plaintext highlighter-rouge">labrador retriever with black hair</code>. Therefore, when there is no target label, we can train models by differentiating these two different pictures using the contrastive loss.</li> </ul> <div class="row mt-3"> <div class="col-sm mt-3 mt-md-0"> <figure> <picture> <source class="responsive-img-srcset" media="(max-width: 480px)" srcset="/2024/assets/img/2024-05-07-robust-foundation-model/proxy_label-480.webp"></source> <source class="responsive-img-srcset" media="(max-width: 800px)" srcset="/2024/assets/img/2024-05-07-robust-foundation-model/proxy_label-800.webp"></source> <source class="responsive-img-srcset" media="(max-width: 1400px)" srcset="/2024/assets/img/2024-05-07-robust-foundation-model/proxy_label-1400.webp"></source> <img src="/2024/assets/img/2024-05-07-robust-foundation-model/proxy_label.png" class="img-fluid" width="auto" height="auto" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"> </picture> </figure> </div> </div> <div class="caption"> The illustration of the proxy label $y^R$ which is a refinement of the label $y_t$. </div> <ul> <li>\(\tilde{x}\) is the adversarial data of $x$. Since the generation procedure of \(\tilde{x}\) in ACL does not use the labels, the adversarial data \(\tilde{x}\) is decided by the natural data \(x\) and the model parameter \(\theta\).</li> </ul> <p>During <strong>the learning procedure</strong>, ACL optimizes the parameters \(\theta\) by maximizing the conditional probabilities both \(p(y^R \mid x)\) and \(p(y^R \mid \tilde{x})\).</p> <h3 id="the-methodology-of-air-">the Methodology of AIR <d-cite key="AIR"></d-cite> </h3> <p><strong>Style-invariant criterion.</strong></p> <p>From the causal view of ACL, the learning procedure should satisfy the style-independent criterion. That is to say, the intervention on the style factor should not affect the conditional probability, i.e., \(p^{do(\tau_i)}(y^R \mid x) = p^{do(\tau_j)}(y^R \mid x)\) where \(do(\tau)\) is the intervention approximated by the data augmentation function $\tau \in \mathcal{T}$.</p> <div class="row mt-3"> <div class="col-sm mt-3 mt-md-0"> <figure> <picture> <source class="responsive-img-srcset" media="(max-width: 480px)" srcset="/2024/assets/img/2024-05-07-robust-foundation-model/AIR_invariant-480.webp"></source> <source class="responsive-img-srcset" media="(max-width: 800px)" srcset="/2024/assets/img/2024-05-07-robust-foundation-model/AIR_invariant-800.webp"></source> <source class="responsive-img-srcset" media="(max-width: 1400px)" srcset="/2024/assets/img/2024-05-07-robust-foundation-model/AIR_invariant-1400.webp"></source> <img src="/2024/assets/img/2024-05-07-robust-foundation-model/AIR_invariant.png" class="img-fluid" width="auto" height="auto" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"> </picture> </figure> </div> </div> <div class="caption"> According to causal reasoning, the style factor $s$ should not affect $p(y^R \mid x)$. </div> <p>Assuming that the path \(x \rightarrow \tilde{x} \rightarrow y^R\) in the causal graph satisfies the Markov condition, we can obtain that</p> \[p(y^R \mid x) = p(y^R \mid \tilde{x})p(\tilde{x} \mid x).\] <p>Therefore, ACL should follow the style-independent criterion as follows:</p> \[p^{do(\tau_i)}(y^R \mid \tilde{x}) p^{do(\tau_i)}(\tilde{x} \mid x) = p^{do(\tau_j)}(y^R \mid \tilde{x}) p^{do(\tau_j)}(\tilde{x} \mid x) \quad \forall \tau_i, \tau_j \in \mathcal{T} .\] <p>The conditional probability \(p^{do(\tau_u)}(y^R \mid \tilde{x})\) for \(u \in \{i,j\}\) is calculated as the cosine similarity between the original data \(x\) and the adversarial data \(\tilde{x}^u\) normalized by the softmax function:</p> \[p^{do(\tau_u)}(y^R \mid \tilde{x}) = \frac{e^{\mathrm{sim} \left(f_\theta(x), f_\theta(\tilde{x}^u) \right)/t}} {\sum\limits_{x_k \in B} e^{\mathrm{sim} \left( f_\theta(x_k), f_\theta(\tilde{x}_k^u) \right)/t}}.\] <p>Note that \(y^R\) is only decided by the content factor \(c\). Empirically, the content factor \(c\) can be approximated by the original data \(x\) from the datasets.</p> <p>The conditional probability \(p^{do(\tau_u)}(\tilde{x} \mid x)\) for \(u \in \{i,j\}\) is calculated as the cosine similarity between the natural data \(x^u\) and the adversarial data \(\tilde{x}^u\) normalized by the softmax function:</p> \[p^{do(\tau_u)}(\tilde{x} | x) = \frac{e^{\mathrm{sim} \left(f_\theta(\tilde{x}^u), f_\theta(x^u) \right)/t}} {\sum\limits_{x_k \in B} e^{\mathrm{sim} \left( f_\theta(\tilde{x}_k^u), f_\theta(x_k^u) \right)/t}}.\] <p><strong>The loss function of AIR.</strong></p> <p>To achieve the style-invariant criterion, AIR is proposed to regulate the representations to be style-independent as follows:</p> \[\mathcal{L}_\mathrm{AIR}(B;\theta, \epsilon) = \mathrm{KL}\left(p^{do(\tau_i)}(y^R \mid \tilde{x}) p^{do(\tau_i)}(\tilde{x} \mid x) \| p^{do(\tau_j)}(y^R \mid \tilde{x}) p^{do(\tau_j)}(\tilde{x} \mid x) ; B \right),\] <p>in which \(\epsilon \geq 0\) is the adversarial budget, \(B\) is a mini-batch, and \(\mathrm{KL}(p(x) \| q(x); B) = \sum_{x \in B} p(x) \log \frac{p(x)}{q(x)}\) denotes the KullbackLeibler (KL) divergence.</p> <p>We provide an illustration of AIR for ACL. The AIR aims to maximize the agreements between the original data and the adversarial view (<span style="color:orange">the dash yellow lines</span>) and the agreements between the natural view and the adversarial view (<span style="color:pink">the dash pink lines</span>).</p> <div class="row mt-3"> <div class="col-sm mt-3 mt-md-0"> <figure> <picture> <source class="responsive-img-srcset" media="(max-width: 480px)" srcset="/2024/assets/img/2024-05-07-robust-foundation-model/AIR_understand-480.webp"></source> <source class="responsive-img-srcset" media="(max-width: 800px)" srcset="/2024/assets/img/2024-05-07-robust-foundation-model/AIR_understand-800.webp"></source> <source class="responsive-img-srcset" media="(max-width: 1400px)" srcset="/2024/assets/img/2024-05-07-robust-foundation-model/AIR_understand-1400.webp"></source> <img src="/2024/assets/img/2024-05-07-robust-foundation-model/AIR_understand.png" class="img-fluid" width="auto" height="auto" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"> </picture> </figure> </div> </div> <div class="caption"> Intuitively, AIR aims to maximize the agreements among different natural views, different adversarial views, and original data. </div> <p><strong>Learning objective of AIR enhanced ACL.</strong></p> <p>The learning objective of AIR is formulated as follows:</p> \[\mathop{\arg\min}_{\theta} \sum_{x \in U} \ell_\mathrm{ACL}(x; \theta) + \lambda_1 \cdot \mathcal{L}_\mathrm{AIR}(U;\theta,0) + \lambda_2 \cdot \mathcal{L}_\mathrm{AIR}(U;\theta,\epsilon),\] <p>where \(\lambda_1 \geq 0\) and \(\lambda_2 \geq 0\) are two hyper-parameters.</p> <p>The official code of AIR is available at <a href="https://github.com/GodXuxilie/Enhancing_ACL_via_AIR" target="_blank" rel="noopener noreferrer">https://github.com/GodXuxilie/Enhancing_ACL_via_AIR</a>.</p> <details><summary>Click here to see the Pytorch code for calculating AIR loss. You can copy-paste it to calculate the AIR loss in convenience. </summary> <figure class="highlight"><pre><code class="language-python" data-lang="python"><span class="kn">import</span> <span class="n">torch</span>
<span class="kn">import</span> <span class="n">torch.nn</span> <span class="k">as</span> <span class="n">nn</span>
<span class="kn">import</span> <span class="n">torch.nn.functional</span> <span class="k">as</span> <span class="n">F</span>

<span class="k">class</span> <span class="nc">AIR</span><span class="p">(</span><span class="n">nn</span><span class="p">.</span><span class="n">Module</span><span class="p">):</span>

    <span class="k">def</span> <span class="nf">__init__</span><span class="p">(</span><span class="n">self</span><span class="p">,</span> <span class="n">normalize</span><span class="o">=</span><span class="bp">True</span><span class="p">,</span> <span class="n">temperature</span><span class="o">=</span><span class="mf">0.5</span><span class="p">):</span>
        <span class="nf">super</span><span class="p">(</span><span class="n">AIR</span><span class="p">,</span> <span class="n">self</span><span class="p">).</span><span class="nf">__init__</span><span class="p">()</span>
        <span class="n">self</span><span class="p">.</span><span class="n">normalize</span> <span class="o">=</span> <span class="n">normalize</span>
        <span class="n">self</span><span class="p">.</span><span class="n">temperature</span> <span class="o">=</span> <span class="n">temperature</span>

    <span class="k">def</span> <span class="nf">forward</span><span class="p">(</span><span class="n">self</span><span class="p">,</span> <span class="n">zi</span><span class="p">,</span> <span class="n">zj</span><span class="p">,</span> <span class="n">zi_adv</span><span class="p">,</span> <span class="n">zj_adv</span><span class="p">,</span> <span class="n">z_orig</span><span class="p">,</span> <span class="n">weight</span><span class="o">=</span><span class="mf">0.5</span><span class="p">,</span> <span class="n">lambda1</span><span class="o">=</span><span class="mf">0.5</span><span class="p">,</span> <span class="n">lambda2</span><span class="o">=</span><span class="mf">0.5</span><span class="p">):</span>
        <span class="c1"># zi: the representation of natural data x^i.
</span>        <span class="c1"># zj: the representation of natural data x^j.
</span>        <span class="c1"># zi_adv: the representation of adversarial data \tilde{x}^i.
</span>        <span class="c1"># zj_adv: the representation of adversarial data \tilde{x}^j.
</span>        <span class="c1"># z_orig: the representation of original data x.
</span>
        <span class="n">bs</span> <span class="o">=</span> <span class="n">zi</span><span class="p">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span>
        <span class="n">labels</span> <span class="o">=</span> <span class="n">torch</span><span class="p">.</span><span class="nf">zeros</span><span class="p">((</span><span class="mi">2</span><span class="o">*</span><span class="n">bs</span><span class="p">,)).</span><span class="nf">long</span><span class="p">().</span><span class="nf">to</span><span class="p">(</span><span class="n">zi</span><span class="p">.</span><span class="n">device</span><span class="p">)</span>
        <span class="n">mask</span> <span class="o">=</span> <span class="n">torch</span><span class="p">.</span><span class="nf">ones</span><span class="p">((</span><span class="n">bs</span><span class="p">,</span> <span class="n">bs</span><span class="p">),</span> <span class="n">dtype</span><span class="o">=</span><span class="nb">bool</span><span class="p">).</span><span class="nf">fill_diagonal_</span><span class="p">(</span><span class="mi">0</span><span class="p">)</span>

        <span class="n">zi_norm</span> <span class="o">=</span> <span class="n">F</span><span class="p">.</span><span class="nf">normalize</span><span class="p">(</span><span class="n">zi</span><span class="p">,</span> <span class="n">p</span><span class="o">=</span><span class="mi">2</span><span class="p">,</span> <span class="n">dim</span><span class="o">=-</span><span class="mi">1</span><span class="p">)</span> <span class="k">if</span> <span class="n">self</span><span class="p">.</span><span class="n">normalize</span> <span class="k">else</span> <span class="n">zi</span>
        <span class="n">zj_norm</span> <span class="o">=</span> <span class="n">F</span><span class="p">.</span><span class="nf">normalize</span><span class="p">(</span><span class="n">zj</span><span class="p">,</span> <span class="n">p</span><span class="o">=</span><span class="mi">2</span><span class="p">,</span> <span class="n">dim</span><span class="o">=-</span><span class="mi">1</span><span class="p">)</span> <span class="k">if</span> <span class="n">self</span><span class="p">.</span><span class="n">normalize</span> <span class="k">else</span> <span class="n">zj</span>
        <span class="n">zi_adv_norm</span> <span class="o">=</span> <span class="n">F</span><span class="p">.</span><span class="nf">normalize</span><span class="p">(</span><span class="n">zi_adv</span><span class="p">,</span> <span class="n">p</span><span class="o">=</span><span class="mi">2</span><span class="p">,</span> <span class="n">dim</span><span class="o">=-</span><span class="mi">1</span><span class="p">)</span> <span class="k">if</span> <span class="n">self</span><span class="p">.</span><span class="n">normalize</span> <span class="k">else</span> <span class="n">zi_adv</span>
        <span class="n">zj_adv_norm</span> <span class="o">=</span> <span class="n">F</span><span class="p">.</span><span class="nf">normalize</span><span class="p">(</span><span class="n">zj_adv</span><span class="p">,</span> <span class="n">p</span><span class="o">=</span><span class="mi">2</span><span class="p">,</span> <span class="n">dim</span><span class="o">=-</span><span class="mi">1</span><span class="p">)</span> <span class="k">if</span> <span class="n">self</span><span class="p">.</span><span class="n">normalize</span> <span class="k">else</span> <span class="n">zj_adv</span>
        <span class="n">zo_norm</span> <span class="o">=</span> <span class="n">F</span><span class="p">.</span><span class="nf">normalize</span><span class="p">(</span><span class="n">z_orig</span><span class="p">,</span> <span class="n">p</span><span class="o">=</span><span class="mi">2</span><span class="p">,</span> <span class="n">dim</span><span class="o">=-</span><span class="mi">1</span><span class="p">)</span> <span class="k">if</span> <span class="n">self</span><span class="p">.</span><span class="n">normalize</span> <span class="k">else</span> <span class="n">z_orig</span>

        <span class="c1">### Adversarial Contrastive Loss ###
</span>        <span class="n">logits_ii</span> <span class="o">=</span> <span class="n">torch</span><span class="p">.</span><span class="nf">mm</span><span class="p">(</span><span class="n">zi_norm</span><span class="p">,</span> <span class="n">zi_norm</span><span class="p">.</span><span class="nf">t</span><span class="p">())</span> <span class="o">/</span> <span class="n">self</span><span class="p">.</span><span class="n">temperature</span>
        <span class="n">logits_ij</span> <span class="o">=</span> <span class="n">torch</span><span class="p">.</span><span class="nf">mm</span><span class="p">(</span><span class="n">zi_norm</span><span class="p">,</span> <span class="n">zj_norm</span><span class="p">.</span><span class="nf">t</span><span class="p">())</span> <span class="o">/</span> <span class="n">self</span><span class="p">.</span><span class="n">temperature</span>
        <span class="n">logits_ji</span> <span class="o">=</span> <span class="n">torch</span><span class="p">.</span><span class="nf">mm</span><span class="p">(</span><span class="n">zj_norm</span><span class="p">,</span> <span class="n">zi_norm</span><span class="p">.</span><span class="nf">t</span><span class="p">())</span> <span class="o">/</span> <span class="n">self</span><span class="p">.</span><span class="n">temperature</span>
        <span class="n">logits_jj</span> <span class="o">=</span> <span class="n">torch</span><span class="p">.</span><span class="nf">mm</span><span class="p">(</span><span class="n">zj_norm</span><span class="p">,</span> <span class="n">zj_norm</span><span class="p">.</span><span class="nf">t</span><span class="p">())</span> <span class="o">/</span> <span class="n">self</span><span class="p">.</span><span class="n">temperature</span>

        <span class="n">logits_ij_pos</span> <span class="o">=</span> <span class="n">logits_ij</span><span class="p">[</span><span class="n">torch</span><span class="p">.</span><span class="nf">logical_not</span><span class="p">(</span><span class="n">mask</span><span class="p">)]</span>                                          
        <span class="n">logits_ji_pos</span> <span class="o">=</span> <span class="n">logits_ji</span><span class="p">[</span><span class="n">torch</span><span class="p">.</span><span class="nf">logical_not</span><span class="p">(</span><span class="n">mask</span><span class="p">)]</span>                                          
        <span class="n">logits_ii_neg</span> <span class="o">=</span> <span class="n">logits_ii</span><span class="p">[</span><span class="n">mask</span><span class="p">].</span><span class="nf">reshape</span><span class="p">(</span><span class="n">bs</span><span class="p">,</span> <span class="o">-</span><span class="mi">1</span><span class="p">)</span>                                            
        <span class="n">logits_ij_neg</span> <span class="o">=</span> <span class="n">logits_ij</span><span class="p">[</span><span class="n">mask</span><span class="p">].</span><span class="nf">reshape</span><span class="p">(</span><span class="n">bs</span><span class="p">,</span> <span class="o">-</span><span class="mi">1</span><span class="p">)</span>                                             
        <span class="n">logits_ji_neg</span> <span class="o">=</span> <span class="n">logits_ji</span><span class="p">[</span><span class="n">mask</span><span class="p">].</span><span class="nf">reshape</span><span class="p">(</span><span class="n">bs</span><span class="p">,</span> <span class="o">-</span><span class="mi">1</span><span class="p">)</span>                                             
        <span class="n">logits_jj_neg</span> <span class="o">=</span> <span class="n">logits_jj</span><span class="p">[</span><span class="n">mask</span><span class="p">].</span><span class="nf">reshape</span><span class="p">(</span><span class="n">bs</span><span class="p">,</span> <span class="o">-</span><span class="mi">1</span><span class="p">)</span>                                             

        <span class="n">pos</span> <span class="o">=</span> <span class="n">torch</span><span class="p">.</span><span class="nf">cat</span><span class="p">((</span><span class="n">logits_ij_pos</span><span class="p">,</span> <span class="n">logits_ji_pos</span><span class="p">),</span> <span class="n">dim</span><span class="o">=</span><span class="mi">0</span><span class="p">).</span><span class="nf">unsqueeze</span><span class="p">(</span><span class="mi">1</span><span class="p">)</span>                         
        <span class="n">neg_i</span> <span class="o">=</span> <span class="n">torch</span><span class="p">.</span><span class="nf">cat</span><span class="p">((</span><span class="n">logits_ii_neg</span><span class="p">,</span> <span class="n">logits_ij_neg</span><span class="p">),</span> <span class="n">dim</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>                                    
        <span class="n">neg_j</span> <span class="o">=</span> <span class="n">torch</span><span class="p">.</span><span class="nf">cat</span><span class="p">((</span><span class="n">logits_ji_neg</span><span class="p">,</span> <span class="n">logits_jj_neg</span><span class="p">),</span> <span class="n">dim</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>                                    
        <span class="n">neg</span> <span class="o">=</span> <span class="n">torch</span><span class="p">.</span><span class="nf">cat</span><span class="p">((</span><span class="n">neg_i</span><span class="p">,</span> <span class="n">neg_j</span><span class="p">),</span> <span class="n">dim</span><span class="o">=</span><span class="mi">0</span><span class="p">)</span>                                                      

        <span class="n">logits</span> <span class="o">=</span> <span class="n">torch</span><span class="p">.</span><span class="nf">cat</span><span class="p">((</span><span class="n">pos</span><span class="p">,</span> <span class="n">neg</span><span class="p">),</span> <span class="n">dim</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>                                                       
        <span class="n">nat_contrastive_loss</span> <span class="o">=</span> <span class="n">F</span><span class="p">.</span><span class="nf">cross_entropy</span><span class="p">(</span><span class="n">logits</span><span class="p">,</span> <span class="n">labels</span><span class="p">)</span>

        <span class="n">logits_ii_adv</span> <span class="o">=</span> <span class="n">torch</span><span class="p">.</span><span class="nf">mm</span><span class="p">(</span><span class="n">zi_adv_norm</span><span class="p">,</span> <span class="n">zi_adv_norm</span><span class="p">.</span><span class="nf">t</span><span class="p">())</span> <span class="o">/</span> <span class="n">self</span><span class="p">.</span><span class="n">temperature</span>
        <span class="n">logits_ij_adv</span> <span class="o">=</span> <span class="n">torch</span><span class="p">.</span><span class="nf">mm</span><span class="p">(</span><span class="n">zi_adv_norm</span><span class="p">,</span> <span class="n">zj_adv_norm</span><span class="p">.</span><span class="nf">t</span><span class="p">())</span> <span class="o">/</span> <span class="n">self</span><span class="p">.</span><span class="n">temperature</span>
        <span class="n">logits_ji_adv</span> <span class="o">=</span> <span class="n">torch</span><span class="p">.</span><span class="nf">mm</span><span class="p">(</span><span class="n">zj_adv_norm</span><span class="p">,</span> <span class="n">zi_adv_norm</span><span class="p">.</span><span class="nf">t</span><span class="p">())</span> <span class="o">/</span> <span class="n">self</span><span class="p">.</span><span class="n">temperature</span>
        <span class="n">logits_jj_adv</span> <span class="o">=</span> <span class="n">torch</span><span class="p">.</span><span class="nf">mm</span><span class="p">(</span><span class="n">zj_adv_norm</span><span class="p">,</span> <span class="n">zj_adv_norm</span><span class="p">.</span><span class="nf">t</span><span class="p">())</span> <span class="o">/</span> <span class="n">self</span><span class="p">.</span><span class="n">temperature</span>

        <span class="n">logits_ij_pos_adv</span> <span class="o">=</span> <span class="n">logits_ij_adv</span><span class="p">[</span><span class="n">torch</span><span class="p">.</span><span class="nf">logical_not</span><span class="p">(</span><span class="n">mask</span><span class="p">)]</span>                                         
        <span class="n">logits_ji_pos_adv</span> <span class="o">=</span> <span class="n">logits_ji_adv</span><span class="p">[</span><span class="n">torch</span><span class="p">.</span><span class="nf">logical_not</span><span class="p">(</span><span class="n">mask</span><span class="p">)]</span>                                          
        <span class="n">logits_ii_neg_adv</span> <span class="o">=</span> <span class="n">logits_ii_adv</span><span class="p">[</span><span class="n">mask</span><span class="p">].</span><span class="nf">reshape</span><span class="p">(</span><span class="n">bs</span><span class="p">,</span> <span class="o">-</span><span class="mi">1</span><span class="p">)</span>                                            
        <span class="n">logits_ij_neg_adv</span> <span class="o">=</span> <span class="n">logits_ij_adv</span><span class="p">[</span><span class="n">mask</span><span class="p">].</span><span class="nf">reshape</span><span class="p">(</span><span class="n">bs</span><span class="p">,</span> <span class="o">-</span><span class="mi">1</span><span class="p">)</span>                                             
        <span class="n">logits_ji_neg_adv</span> <span class="o">=</span> <span class="n">logits_ji_adv</span><span class="p">[</span><span class="n">mask</span><span class="p">].</span><span class="nf">reshape</span><span class="p">(</span><span class="n">bs</span><span class="p">,</span> <span class="o">-</span><span class="mi">1</span><span class="p">)</span>                                             
        <span class="n">logits_jj_neg_adv</span> <span class="o">=</span> <span class="n">logits_jj_adv</span><span class="p">[</span><span class="n">mask</span><span class="p">].</span><span class="nf">reshape</span><span class="p">(</span><span class="n">bs</span><span class="p">,</span> <span class="o">-</span><span class="mi">1</span><span class="p">)</span>                                             

        <span class="n">pos_adv</span> <span class="o">=</span> <span class="n">torch</span><span class="p">.</span><span class="nf">cat</span><span class="p">((</span><span class="n">logits_ij_pos_adv</span><span class="p">,</span> <span class="n">logits_ji_pos_adv</span><span class="p">),</span> <span class="n">dim</span><span class="o">=</span><span class="mi">0</span><span class="p">).</span><span class="nf">unsqueeze</span><span class="p">(</span><span class="mi">1</span><span class="p">)</span>                         
        <span class="n">neg_i_adv</span> <span class="o">=</span> <span class="n">torch</span><span class="p">.</span><span class="nf">cat</span><span class="p">((</span><span class="n">logits_ii_neg_adv</span><span class="p">,</span> <span class="n">logits_ij_neg_adv</span><span class="p">),</span> <span class="n">dim</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>                                    
        <span class="n">neg_j_adv</span> <span class="o">=</span> <span class="n">torch</span><span class="p">.</span><span class="nf">cat</span><span class="p">((</span><span class="n">logits_ji_neg_adv</span><span class="p">,</span> <span class="n">logits_jj_neg_adv</span><span class="p">),</span> <span class="n">dim</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>                                    
        <span class="n">neg_adv</span> <span class="o">=</span> <span class="n">torch</span><span class="p">.</span><span class="nf">cat</span><span class="p">((</span><span class="n">neg_i_adv</span><span class="p">,</span> <span class="n">neg_j_adv</span><span class="p">),</span> <span class="n">dim</span><span class="o">=</span><span class="mi">0</span><span class="p">)</span>                                                      

        <span class="n">logits_adv</span> <span class="o">=</span> <span class="n">torch</span><span class="p">.</span><span class="nf">cat</span><span class="p">((</span><span class="n">pos_adv</span><span class="p">,</span> <span class="n">neg_adv</span><span class="p">),</span> <span class="n">dim</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>                                                       
        <span class="n">adv_contrastive_loss</span> <span class="o">=</span> <span class="n">F</span><span class="p">.</span><span class="nf">cross_entropy</span><span class="p">(</span><span class="n">logits_adv</span><span class="p">,</span> <span class="n">labels</span><span class="p">)</span>

        <span class="c1">### Adversarial Invariant Regularization ###
</span>        <span class="n">logits_io</span> <span class="o">=</span> <span class="n">torch</span><span class="p">.</span><span class="nf">mm</span><span class="p">(</span><span class="n">zi_norm</span><span class="p">,</span> <span class="n">zo_norm</span><span class="p">.</span><span class="nf">t</span><span class="p">())</span> <span class="o">/</span> <span class="n">self</span><span class="p">.</span><span class="n">temperature</span>
        <span class="n">logits_jo</span> <span class="o">=</span> <span class="n">torch</span><span class="p">.</span><span class="nf">mm</span><span class="p">(</span><span class="n">zj_norm</span><span class="p">,</span> <span class="n">zo_norm</span><span class="p">.</span><span class="nf">t</span><span class="p">())</span> <span class="o">/</span> <span class="n">self</span><span class="p">.</span><span class="n">temperature</span>
        <span class="n">probs_io_zi</span> <span class="o">=</span> <span class="n">F</span><span class="p">.</span><span class="nf">softmax</span><span class="p">(</span><span class="n">logits_io</span><span class="p">[</span><span class="n">torch</span><span class="p">.</span><span class="nf">logical_not</span><span class="p">(</span><span class="n">mask</span><span class="p">)],</span> <span class="o">-</span><span class="mi">1</span><span class="p">)</span>
        <span class="n">probs_jo_zj</span> <span class="o">=</span> <span class="n">F</span><span class="p">.</span><span class="nf">log_softmax</span><span class="p">(</span><span class="n">logits_jo</span><span class="p">[</span><span class="n">torch</span><span class="p">.</span><span class="nf">logical_not</span><span class="p">(</span><span class="n">mask</span><span class="p">)],</span> <span class="o">-</span><span class="mi">1</span><span class="p">)</span>
        <span class="n">AIR_standard</span> <span class="o">=</span> <span class="n">F</span><span class="p">.</span><span class="nf">kl_div</span><span class="p">(</span><span class="n">probs_io_zi</span><span class="p">,</span> <span class="n">probs_jo_zj</span><span class="p">,</span> <span class="n">log_target</span><span class="o">=</span><span class="bp">True</span><span class="p">,</span> <span class="n">reduction</span><span class="o">=</span><span class="sh">"</span><span class="s">sum</span><span class="sh">"</span><span class="p">)</span>

        <span class="n">logits_io</span> <span class="o">=</span> <span class="n">torch</span><span class="p">.</span><span class="nf">mm</span><span class="p">(</span><span class="n">zi_adv_norm</span><span class="p">,</span> <span class="n">zi_norm</span><span class="p">.</span><span class="nf">t</span><span class="p">())</span> <span class="o">/</span> <span class="n">self</span><span class="p">.</span><span class="n">temperature</span>
        <span class="n">logits_jo</span> <span class="o">=</span> <span class="n">torch</span><span class="p">.</span><span class="nf">mm</span><span class="p">(</span><span class="n">zj_adv_norm</span><span class="p">,</span> <span class="n">zj_norm</span><span class="p">.</span><span class="nf">t</span><span class="p">())</span> <span class="o">/</span> <span class="n">self</span><span class="p">.</span><span class="n">temperature</span>
        <span class="n">probs_io_zi_adv_consis</span> <span class="o">=</span> <span class="n">F</span><span class="p">.</span><span class="nf">softmax</span><span class="p">(</span><span class="n">logits_io</span><span class="p">[</span><span class="n">torch</span><span class="p">.</span><span class="nf">logical_not</span><span class="p">(</span><span class="n">mask</span><span class="p">)],</span> <span class="o">-</span><span class="mi">1</span><span class="p">)</span>
        <span class="n">probs_jo_zj_adv_consis</span> <span class="o">=</span> <span class="n">F</span><span class="p">.</span><span class="nf">softmax</span><span class="p">(</span><span class="n">logits_jo</span><span class="p">[</span><span class="n">torch</span><span class="p">.</span><span class="nf">logical_not</span><span class="p">(</span><span class="n">mask</span><span class="p">)],</span> <span class="o">-</span><span class="mi">1</span><span class="p">)</span>

        <span class="n">logits_io</span> <span class="o">=</span> <span class="n">torch</span><span class="p">.</span><span class="nf">mm</span><span class="p">(</span><span class="n">zi_adv_norm</span><span class="p">,</span> <span class="n">zo_norm</span><span class="p">.</span><span class="nf">t</span><span class="p">())</span> <span class="o">/</span> <span class="n">self</span><span class="p">.</span><span class="n">temperature</span>
        <span class="n">logits_jo</span> <span class="o">=</span> <span class="n">torch</span><span class="p">.</span><span class="nf">mm</span><span class="p">(</span><span class="n">zj_adv_norm</span><span class="p">,</span> <span class="n">zo_norm</span><span class="p">.</span><span class="nf">t</span><span class="p">())</span> <span class="o">/</span> <span class="n">self</span><span class="p">.</span><span class="n">temperature</span>
        <span class="n">probs_io_zi_adv</span> <span class="o">=</span> <span class="n">F</span><span class="p">.</span><span class="nf">softmax</span><span class="p">(</span><span class="n">logits_io</span><span class="p">[</span><span class="n">torch</span><span class="p">.</span><span class="nf">logical_not</span><span class="p">(</span><span class="n">mask</span><span class="p">)],</span> <span class="o">-</span><span class="mi">1</span><span class="p">)</span>
        <span class="n">probs_jo_zj_adv</span> <span class="o">=</span> <span class="n">F</span><span class="p">.</span><span class="nf">softmax</span><span class="p">(</span><span class="n">logits_jo</span><span class="p">[</span><span class="n">torch</span><span class="p">.</span><span class="nf">logical_not</span><span class="p">(</span><span class="n">mask</span><span class="p">)],</span> <span class="o">-</span><span class="mi">1</span><span class="p">)</span>

        <span class="n">probs_io_zi_adv</span> <span class="o">=</span> <span class="n">torch</span><span class="p">.</span><span class="nf">mul</span><span class="p">(</span><span class="n">probs_io_zi_adv</span><span class="p">,</span> <span class="n">probs_io_zi_adv_consis</span><span class="p">)</span>
        <span class="n">probs_jo_zj_adv</span> <span class="o">=</span> <span class="n">torch</span><span class="p">.</span><span class="nf">mul</span><span class="p">(</span><span class="n">probs_jo_zj_adv</span><span class="p">,</span> <span class="n">probs_jo_zj_adv_consis</span><span class="p">)</span>
        <span class="n">AIR_robust</span> <span class="o">=</span> <span class="n">F</span><span class="p">.</span><span class="nf">kl_div</span><span class="p">(</span><span class="n">probs_io_zi_adv</span><span class="p">,</span> <span class="n">torch</span><span class="p">.</span><span class="nf">log</span><span class="p">(</span><span class="n">probs_jo_zj_adv</span><span class="p">),</span> <span class="n">log_target</span><span class="o">=</span><span class="bp">True</span><span class="p">,</span> <span class="n">reduction</span><span class="o">=</span><span class="sh">"</span><span class="s">sum</span><span class="sh">"</span><span class="p">)</span>

        <span class="nf">return </span><span class="p">(</span><span class="mi">1</span> <span class="o">-</span> <span class="n">weight</span><span class="p">)</span> <span class="o">*</span> <span class="n">nat_contrastive_loss</span> <span class="o">+</span> <span class="p">(</span><span class="mi">1</span> <span class="o">+</span> <span class="n">weight</span><span class="p">)</span> <span class="o">*</span> <span class="n">adv_contrastive_loss</span> <span class="o">+</span> <span class="n">lambda1</span> <span class="o">*</span> <span class="n">AIR_standard</span> <span class="o">+</span> <span class="n">lambda2</span> <span class="o">*</span> <span class="n">AIR_robust</span></code></pre></figure> </details> <p>Besides, you can use the following script to conduct robust self-supervised pre-training via AIR using ResNet-18 on CIFAR-10:</p> <figure class="highlight"><pre><code class="language-bash" data-lang="bash"><span class="c"># Pre-training stage via AIR</span>
git clone https://github.com/GodXuxilie/Enhancing_ACL_via_AIR.git
<span class="nb">cd </span>Enhancing_ACL_via_AIR
<span class="nv">PRE_TRAIN_DIR</span><span class="o">=</span>AIR_ResNet18_cifar10
python pretraining.py <span class="nv">$PRE_TRAIN_DIR</span> <span class="nt">--dataset</span> cifar10 <span class="nt">--model</span> r18 <span class="nt">--DynAug</span></code></pre></figure> <h3 id="empirical-results">Empirical Results</h3> <p><strong>AIR yields state-of-the-art cross-task robustness transferability against adversarial attacks.</strong></p> <ul> <li>\(\mathcal{D}_1 \rightarrow \mathcal{D}_2\) refers to that the model is pre-trained on dataset \(\mathcal{D}_1\) and fine-tuned on downstream dataset \(\mathcal{D}_2\).</li> <li> <code class="language-plaintext highlighter-rouge">SA</code> refers the standard accuracy calculated as the average accuracy on the natural test data in the downstream dataset \(\mathcal{D}_2\).</li> <li> <code class="language-plaintext highlighter-rouge">AA</code> refers to the robust accuracy calculated as the average accuracy on the adversarial test data generated via <a href="https://github.com/fra31/auto-attack" target="_blank" rel="noopener noreferrer">adversarial attacks</a> in the downstream dataset \(\mathcal{D}_2\).</li> </ul> <div class="row mt-3"> <div class="col-sm mt-3 mt-md-0"> <figure> <picture> <source class="responsive-img-srcset" media="(max-width: 480px)" srcset="/2024/assets/img/2024-05-07-robust-foundation-model/AIR_cross_attack-480.webp"></source> <source class="responsive-img-srcset" media="(max-width: 800px)" srcset="/2024/assets/img/2024-05-07-robust-foundation-model/AIR_cross_attack-800.webp"></source> <source class="responsive-img-srcset" media="(max-width: 1400px)" srcset="/2024/assets/img/2024-05-07-robust-foundation-model/AIR_cross_attack-1400.webp"></source> <img src="/2024/assets/img/2024-05-07-robust-foundation-model/AIR_cross_attack.png" class="img-fluid" width="auto" height="auto" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"> </picture> </figure> </div> </div> <p><strong>AIR yields state-of-the-art cross-task robustness transferability against common corruptions.</strong></p> <p><code class="language-plaintext highlighter-rouge">CS-#</code> refers to the the average accuracy evaluated on the test data under common corruptions with corruption severity (CS) of <code class="language-plaintext highlighter-rouge">#</code> \(\in\) {1,3,5} in the downstream dataset \(\mathcal{D}_2\).</p> <div class="row mt-3"> <div class="col-sm mt-3 mt-md-0"> <figure> <picture> <source class="responsive-img-srcset" media="(max-width: 480px)" srcset="/2024/assets/img/2024-05-07-robust-foundation-model/AIR_cross_corrup-480.webp"></source> <source class="responsive-img-srcset" media="(max-width: 800px)" srcset="/2024/assets/img/2024-05-07-robust-foundation-model/AIR_cross_corrup-800.webp"></source> <source class="responsive-img-srcset" media="(max-width: 1400px)" srcset="/2024/assets/img/2024-05-07-robust-foundation-model/AIR_cross_corrup-1400.webp"></source> <img src="/2024/assets/img/2024-05-07-robust-foundation-model/AIR_cross_corrup.png" class="img-fluid" width="auto" height="auto" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"> </picture> </figure> </div> </div> <p>To reproduce the above results of the transferability from CIFAR-10 to CIFAR-100, you can use the following scripts.</p> <ul> <li>At the pre-training stage, you can conduct AIR using ResNet-18 on CIFAR-10.</li> </ul> <figure class="highlight"><pre><code class="language-bash" data-lang="bash"><span class="c"># Pre-training stage using AIR</span>
git clone https://github.com/GodXuxilie/Enhancing_ACL_via_AIR.git
<span class="nb">cd </span>Enhancing_ACL_via_AIR
<span class="nv">PRE_TRAIN_DIR</span><span class="o">=</span>AIR_ResNet18_cifar10
python pretraining.py <span class="nv">$PRETRAIN_DIR</span> <span class="nt">--dataset</span> cifar10 <span class="nt">--model</span> r18 <span class="nt">--DynAug</span></code></pre></figure> <ul> <li>At the fine-tuning stage, you can fine-tune the pre-trained ResNet-18 to downstream task CIFAR-100. During the fine-tuning stage, the following script will automatically conduct all three fine-tuning modes (i.e., SLF, ALF, and AFF). After the fine-tuning stage, you can check the standard accuracy, the robust accuracy under adversarial attacks and common cottuptions under each fine-tuning method from a log file at <code class="language-plaintext highlighter-rouge">$FINETUNE_DIR/results/log.txt</code>.</li> </ul> <figure class="highlight"><pre><code class="language-bash" data-lang="bash"><span class="c"># Fine-tuning stage</span>
<span class="nb">cd </span>Enhancing_ACL_via_AIR
<span class="nv">PRE_TRAIN_DIR</span><span class="o">=</span>AIR_ResNet18_cifar10
<span class="nv">FINETUNE_DIR</span><span class="o">=</span>AIR_ResNet18_cifar10_cifar100
python finetuning.py <span class="nt">--experiment</span> <span class="nv">$EXP_DIR</span> <span class="se">\</span>
                     <span class="nt">--checkpoint</span> ./checkpoints/<span class="nv">$PRE_TRAIN_DIR</span>/model.pt <span class="se">\</span>
                     <span class="nt">--dataset</span> cifar100 <span class="se">\</span>
                     <span class="nt">--model</span> r18 <span class="se">\</span>
                     <span class="nt">--mode</span> ALL <span class="se">\</span>
                     <span class="nt">--eval-AA</span> <span class="nt">--eval-OOD</span> <span class="nt">--pretraining</span> DynACL_AIR</code></pre></figure> <h3 id="robust-self-supervised-learning-robustssl-benchmark-the-website-of-robustssl-benchmark-is-at-httpsrobustsslgithubio">Robust Self-Supervised Learning (RobustSSL) Benchmark <d-footnote>The website of RobustSSL Benchmark is at https://robustssl.github.io/.</d-footnote> </h3> <p><strong>AIR ranks FIRST in <a href="https://robustssl.github.io/" target="_blank" rel="noopener noreferrer">RobustSSL Benchmark</a>!</strong> For more information regarding the leaderboards, please check the website of <a href="https://robustssl.github.io/" target="_blank" rel="noopener noreferrer">RobustSSL Benchmark</a>.</p> <div class="row mt-3"> <div class="col-sm mt-3 mt-md-0"> <figure> <picture> <source class="responsive-img-srcset" media="(max-width: 480px)" srcset="/2024/assets/img/2024-05-07-robust-foundation-model/leaderboard-480.webp"></source> <source class="responsive-img-srcset" media="(max-width: 800px)" srcset="/2024/assets/img/2024-05-07-robust-foundation-model/leaderboard-800.webp"></source> <source class="responsive-img-srcset" media="(max-width: 1400px)" srcset="/2024/assets/img/2024-05-07-robust-foundation-model/leaderboard-1400.webp"></source> <img src="/2024/assets/img/2024-05-07-robust-foundation-model/leaderboard.png" class="img-fluid" width="auto" height="auto" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"> </picture> </figure> </div> </div> <div class="caption"> A screenshot of the leaderboard shown in RobustSSL Benchmark. </div> <h2 id="efficient-acl-via-robustness-aware-coreset-selection-rcs">Efficient ACL via Robustness-Aware Coreset Selection (RCS)</h2> <p>Here, we introduce the NeurIPS 2023 spotlight paper <d-cite key="RCS"></d-cite> which proposes Robustness-Aware Coreset Selection (RCS) that selects an informative coreset without label annotations to speed up ACL. Theoretically, Xu et al. (2023) <d-cite key="RCS"></d-cite> show that a greedy search algorithm can efficiently find the coreset. Empirically, RCS can speed up both ACL and supervised robust pre-training by a large margin on CIFAR and ImageNet-1K datasets without significantly hurting the robustness transferability. This paper <d-cite key="RCS"></d-cite> for the first time proves theconcept of the possibility of applying ACL on large-scale datasets.</p> <h3 id="motivationacl-is-inefficient">MotivationACL is Inefficient</h3> <p>ACL is computationally prohibitive on large-scale datasets since generating adversarial data requires expensive computational overheads.</p> <p>Empirically, ACL on the entire ImageNet-1K dataset (1,281,167 training data points) requires about <strong>650 hours</strong> evaluated on RTX A5000 GPUs. Due to the inefficiency of ACL, ACL has not yet been applied to ImageNet-1K datasets without RCS.</p> <div class="row mt-3"> <div class="col-sm mt-3 mt-md-0"> <figure> <picture> <source class="responsive-img-srcset" media="(max-width: 480px)" srcset="/2024/assets/img/2024-05-07-robust-foundation-model/PGD-480.webp"></source> <source class="responsive-img-srcset" media="(max-width: 800px)" srcset="/2024/assets/img/2024-05-07-robust-foundation-model/PGD-800.webp"></source> <source class="responsive-img-srcset" media="(max-width: 1400px)" srcset="/2024/assets/img/2024-05-07-robust-foundation-model/PGD-1400.webp"></source> <img src="/2024/assets/img/2024-05-07-robust-foundation-model/PGD.png" class="img-fluid" width="100" height="100" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"> </picture> </figure> </div> </div> <div class="caption"> ACL is inefficient because $T$ PGD steps require expensive computational overheads. </div> <h3 id="the-methodology-of-rcs-">the Methodology of RCS <d-cite key="RCS"></d-cite> </h3> <p><strong>Intuition of RCS.</strong></p> <p>To speed up ACL, RCS takes an intuitive idea which is to find an informative training subset (called coreset). The coreset can directly decrease the number of training samples, thus significantly accelerating ACL. Besides, since the coreset is informative, which is beneficial in improving \(f\)s adversarial robustness, it should guarantee the ACL to output an effective robust foundation model.</p> <div class="row mt-3"> <div class="col-sm mt-3 mt-md-0"> <figure> <picture> <source class="responsive-img-srcset" media="(max-width: 480px)" srcset="/2024/assets/img/2024-05-07-robust-foundation-model/intuition-480.webp"></source> <source class="responsive-img-srcset" media="(max-width: 800px)" srcset="/2024/assets/img/2024-05-07-robust-foundation-model/intuition-800.webp"></source> <source class="responsive-img-srcset" media="(max-width: 1400px)" srcset="/2024/assets/img/2024-05-07-robust-foundation-model/intuition-1400.webp"></source> <img src="/2024/assets/img/2024-05-07-robust-foundation-model/intuition.png" class="img-fluid" width="auto" height="auto" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"> </picture> </figure> </div> </div> <div class="caption"> RCS generates an informative coreset to make ACL efficiently obtain an effective robust foundation model.<d-footnote>Image from https://medium.com/analytics-vidhya/sampling-statistical-approach-in-machine-learning-4903c40ebf86.</d-footnote> </div> <p><strong>Representational Distance (RD) as a measurement of \(f\)s adversarial robustness without labels.</strong></p> <p>RD of a data point \(\ell_\mathrm{RD}(x;\theta)\) is quantified by the representational distance between the natural data and its adversarial counterpart, i.e.,</p> \[\ell_{\mathrm{RD}}(x; \theta) = d(g \circ f_\theta(\tilde{x}), g \circ f_\theta(x)) \quad \mathrm{s.t.} \quad \tilde{x} = \mathop{\arg\max}_{x^{\prime} \in \mathcal{B}_\epsilon[x]} \quad d(g \circ f_\theta(x^{\prime}), g \circ f_\theta(x)),\] <p>in which the PGD method is used to generate adversarial data \(\tilde{x}\) within the \(\epsilon\)-ball centered at \(x\) and \(d(\cdot, \cdot): \mathcal{V} \times \mathcal{V} \rightarrow \mathbb{R}\) is a distance function, such as the KL divergence. The smaller the RD is, the representations are of less sensitivity to adversarial perturbations, thus being more adversarially robust.</p> <p><strong>Objective function of RCS.</strong></p> <p>To realize the intuitive idea, RCS is formulated as follows:</p> \[S^* = \mathop{\arg\min}_{S \subseteq X, |S|/|X| = k} \mathcal{L}_{\mathrm{RD}}(U; \theta(S)),\] \[\theta(S) = \mathop{\arg\min}_{\theta} \mathcal{L}_\mathrm{ACL}(S; \theta),\] <p>in which \(S^*\) is the coreset, \(U\) is an unlabled validation set, \(k \in (0,1]\) is subset fraction that controls the size of coreset, and \(\mathcal{L}_{\mathrm{RD}}(U; \theta(S)) = \sum_{x \in U} \ell_\mathrm{RD}(x; \theta(S))\), and \(\mathcal{L}_\mathrm{ACL}(S; \theta) = \sum_{x \in S} \ell_\mathrm{ACL}(x; \theta)\).</p> <p>Intuitively, given a coreset \(S^*\), after the model parameters are updated to \(\theta(S^{*})\) via minimizing the ACL loss on the coreset \(\mathcal{L}_\mathrm{ACL}(S^*; \theta)\), the model will achieve the minimizied RD loss on the validation dataset \(\mathcal{L}_{\mathrm{RD}}(U; \theta(S^*))\), thus being adversarially robust.</p> <p>Then, RCS can be converted into a problem of maximizing a set function subject to a cardinality constraint as follows:</p> \[S^* = \mathop{\arg\max}_{S \subseteq X, |S|/|X| = k} G_\theta(S),\] \[G_\theta(S \subseteq X) \triangleq - \mathcal{L}_\mathrm{RD}(U; \theta(S)) = - \mathcal{L}_\mathrm{RD}(U; \theta - \eta \nabla_\theta \mathcal{L}_\mathrm{ACL}(S; \theta)),\] <p>where \(G:2^\mathcal{X} \rightarrow \mathbb{R}\) is a set function, \(\theta(S)\) is estimated using the one-step approximation and \(\eta \in \mathbb{R}^+\) is the learning rate.</p> <p><strong>RCS via Greedy Search.</strong></p> <p>The vanilla solution of traversing all subsets and selecting the subset that has the largest \(G_\theta(S)\) is intractable. Xu et al. (2023) <d-cite key="RCS"></d-cite> show that the set function \(G_\theta(S)\) satisfies the following two critical properties, which motivates a greedy search to efficiently search for the coreset.</p> <p>The set function \(G_\theta(S)\) is proved as submodular<d-footnote>In reality, the authors of RCS <d-cite key="RCS"></d-cite> rigorously proved a proxy set function as weakly submodular. Further, the authors of RCS proved that the greedy search algorithm provides a guaranteed lower bound for the proposed set function maximization problem based on a weakly submodular proxy set function. For more details, please refer to the paper of RCS.</d-footnote> which satisfies the following two properties:</p> <ul> <li>Monotonicity: As more data is added to the set, the representation becomes better.<br> \(G(x\mid X)=G(S \cup \{x\}) - G(S) \geq 0\) for any \(S \subseteq X\) and \(x \in X \setminus S\).</li> <li>Diminishing returns: As the set has more data, the marginal gain of extra data for learning representations gradually diminishes. <br> \(\mathop{\forall}\limits_{A,B \mid A \subseteq B} G_\theta(x \mid A) \geq G_\theta(x \mid B)\).</li> </ul> <p>Therefore, RCS greedily searches for the data \(x\) that has the largest marginal gain and then adds them into the coreset.</p> <p><strong>Pseudo-code of efficient ACL via RCS.</strong></p> <ul> <li>Step 1 (Warm-up): Warm up training on the entire training set to find a better starting point \(f_\theta\).</li> <li> <strong>Step 2.1 (RCS)</strong>: \(S \gets\emptyset\). \(\theta' \gets \theta\). Compute gradients \(Q \gets \{ q_k = \nabla_\theta \mathcal{L}_\mathrm{ACL}(x_k; \theta) \mid \forall x_k \in X \}\) on unlabeled training dataset \(X\).</li> <li> <strong>Step 2.2 (RCS)</strong>: Compute gradients \(q_U \gets \nabla_\theta \mathcal{L}_\mathrm{RD}(U; \theta')\) on unlabeled validation dataset \(U\).</li> <li> <strong>Step 2.3 (RCS)</strong>: Select a data \(x_k\), whose gradient \(q_k\) matches best with \(q_U\), i.e., \(\mathop{\arg\max}_k \{q_k^\top q_U \}\).</li> <li> <strong>Step 2.4 (RCS)</strong>: \(S \gets S \cup \{x_k\}\), \(X \gets X \setminus \{ x_k \}\), \(\theta' \gets \theta' - \eta' q_k\).</li> <li> <strong>Step 2.5 (RCS)</strong>: Repeat Steps 2.2-2.4 until \(\mid S\mid/\mid X\mid = k\).</li> <li>Step 3 (ACL training): Update parameters \(\theta \gets \theta - \eta \nabla_\theta \mathcal{L}_\mathrm{ACL}(S; \theta)\).</li> <li>Step 4: Every a few epochs, go to Step 2.1 to generate a new coreset; otherwise go to Step 3 to update model parameters. The algorithm stops when reaching the final training epoch.</li> </ul> <div class="row mt-3"> <div class="col-sm mt-3 mt-md-0"> <figure> <picture> <source class="responsive-img-srcset" media="(max-width: 480px)" srcset="/2024/assets/img/2024-05-07-robust-foundation-model/RCS_algo-480.webp"></source> <source class="responsive-img-srcset" media="(max-width: 800px)" srcset="/2024/assets/img/2024-05-07-robust-foundation-model/RCS_algo-800.webp"></source> <source class="responsive-img-srcset" media="(max-width: 1400px)" srcset="/2024/assets/img/2024-05-07-robust-foundation-model/RCS_algo-1400.webp"></source> <img src="/2024/assets/img/2024-05-07-robust-foundation-model/RCS_algo.png" class="img-fluid" width="auto" height="auto" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"> </picture> </figure> </div> </div> <div class="caption"> A pipeline of efficient ACL via RCS. After the warm-up periods, the model is trained on the coreset. Thus, RCS makes the training procedure much more efficient by decreasing the number of training data. </div> <p>Intuitively, RCS greedily selects and adds the data \(x\) whose training loss gradient (i.e., \(\nabla_\theta\mathcal{L}_\mathrm{ACL}(\{x\}, \theta)\)) and validation loss gradient (i.e, \(\nabla_\theta\mathcal{L}_\mathcal{RD}(U; \theta(S))\)) have the most similarity into the coreset. In this way, training on the data selected by RCS is most beneficial in optimizing the RD loss, which is thus most helpful to improve \(f\)s adversarial robustness.</p> <p>The official code of RCS is available at <a href="https://github.com/GodXuxilie/Efficient_ACL_via_RCS" target="_blank" rel="noopener noreferrer">https://github.com/GodXuxilie/Efficient_ACL_via_RCS</a>.</p> <h3 id="experimental-results">Experimental Results</h3> <p><strong>RCS significantly speeds up ACL on CIFAR-10.</strong></p> <ul> <li>The term <code class="language-plaintext highlighter-rouge">speed-up ratio</code> refers to the ratio of the time consumption of pre-training on the training set to the the time consumption of pre-training on the training subset. Thus, the larger the speed-up ratio is, the more efficient the pre-training procedure is.</li> <li>The terms <code class="language-plaintext highlighter-rouge">standard test accuracy</code> and <code class="language-plaintext highlighter-rouge">robust test accuracy</code> refer to the average accuracy evaluated on natural test data and adversarial test data, respectively. Thus, the higher the line is, the more effective the pre-training method is.</li> </ul> <p>The results obtained by RCS located in the upper-right corner is more efficient and more effective.</p> <div class="row mt-3"> <div class="col-sm mt-3 mt-md-0"> <figure> <picture> <source class="responsive-img-srcset" media="(max-width: 480px)" srcset="/2024/assets/img/2024-05-07-robust-foundation-model/RCS_exp1-480.webp"></source> <source class="responsive-img-srcset" media="(max-width: 800px)" srcset="/2024/assets/img/2024-05-07-robust-foundation-model/RCS_exp1-800.webp"></source> <source class="responsive-img-srcset" media="(max-width: 1400px)" srcset="/2024/assets/img/2024-05-07-robust-foundation-model/RCS_exp1-1400.webp"></source> <img src="/2024/assets/img/2024-05-07-robust-foundation-model/RCS_exp1.png" class="img-fluid" width="auto" height="auto" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"> </picture> </figure> </div> </div> <p>To reproduce the above results of the robustness transferability from CIFAR-10 to CIFAR-100, you can use the following scripts.</p> <ul> <li>At the pre-training stage, you can conduct ACL via RCS using ResNet-18 on CIFAR-10.</li> </ul> <figure class="highlight"><pre><code class="language-bash" data-lang="bash"><span class="c"># Pre-training stage using RCS</span>
git clone https://github.com/GodXuxilie/Efficient_ACL_via_RCS.git
<span class="nb">cd </span>Efficient_ACL_via_RCS/ACL_RCS/small_scale_datasets
<span class="nv">PRE_TRAIN_DIR</span><span class="o">=</span>ACL_RCS_ResNet18_cifar10
python DynACL_RCS.py <span class="nv">$PRE_TRAIN_DIR</span> <span class="nt">--ACL_DS</span> <span class="nt">--dataset</span> cifar10 <span class="nt">--fraction</span> 0.2</code></pre></figure> <ul> <li>At the fine-tuning stage, you can fine-tune the pre-trained ResNet-18 on CIFAR-100. The test accuracy are saved in <code class="language-plaintext highlighter-rouge">$FINETUNE_DIR/results/log.txt</code>.</li> </ul> <figure class="highlight"><pre><code class="language-bash" data-lang="bash"><span class="c"># Fine-tuning stage (SLF, ALF, AFF)</span>
<span class="nb">cd </span>Efficient_ACL_via_RCS/ACL_RCS/small_scale_datasets
<span class="nv">PRE_TRAIN_DIR</span><span class="o">=</span>ACL_RCS_ResNet18_cifar10
<span class="nv">FINETUNE_DIR</span><span class="o">=</span>ACL_RCS_ResNet18_cifar10_cifar100
python finetuning.py <span class="nt">--experiment</span> <span class="nv">$FINETUNE_DIR</span> <span class="se">\</span>
                     <span class="nt">--checkpoint</span> ./checkpoints/<span class="nv">$PRE_TRAIN_DIR</span>/model.pt <span class="se">\</span>
                     <span class="nt">--dataset</span> cifar100 <span class="se">\</span>
                     <span class="nt">--model</span> r18 <span class="se">\</span>
                     <span class="nt">--mode</span> ALL <span class="nt">--eval-AA</span> <span class="nt">--eval-OOD</span> <span class="nt">--pretraining</span> DynACL_RCS</code></pre></figure> <p><strong>For the first time, ACL was conducted efficiently on ImageNet-1K via RCS.</strong> The results prove the possibility of applying ACL on large-scale datasets. Here, <code class="language-plaintext highlighter-rouge">SA</code> refers to standard test accuracy and <code class="language-plaintext highlighter-rouge">RA</code> refers to the robust test accuracy.</p> <div class="row mt-3"> <div class="col-sm mt-3 mt-md-0"> <figure> <picture> <source class="responsive-img-srcset" media="(max-width: 480px)" srcset="/2024/assets/img/2024-05-07-robust-foundation-model/RCS_exp2-480.webp"></source> <source class="responsive-img-srcset" media="(max-width: 800px)" srcset="/2024/assets/img/2024-05-07-robust-foundation-model/RCS_exp2-800.webp"></source> <source class="responsive-img-srcset" media="(max-width: 1400px)" srcset="/2024/assets/img/2024-05-07-robust-foundation-model/RCS_exp2-1400.webp"></source> <img src="/2024/assets/img/2024-05-07-robust-foundation-model/RCS_exp2.png" class="img-fluid" width="auto" height="auto" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"> </picture> </figure> </div> </div> <p>To reproduce the above results of the robustness transferability from ImageNet-1K to CIFAR-10, you can use the following scripts.</p> <ul> <li>At the pre-training stage, you can ACL via RCS using Wide ResNet with width 10 and depth 28 (WRN-28-10) on ImageNet-1K of \(32 \times 32\) resolution.</li> </ul> <figure class="highlight"><pre><code class="language-bash" data-lang="bash"><span class="c"># Pre-training stage using RCS</span>
git clone https://github.com/GodXuxilie/Efficient_ACL_via_RCS.git
<span class="nb">cd </span>Efficient_ACL_via_RCS/ACL_RCS/ImageNet_32
<span class="nv">PRE_TRAIN_DIR</span><span class="o">=</span>ACL_RCS_WRN_ImageNet
python ACL_RCS.py <span class="nv">$PRE_TRAIN_DIR</span> <span class="nt">--gpu</span> 0,1,2,3 <span class="nt">--ACL_DS</span> <span class="nt">--fraction</span> 0.05</code></pre></figure> <ul> <li>At the fine-tuning stage, you can fine-tune the ImageNet-1K pre-trained models on CIFAR-10.</li> </ul> <figure class="highlight"><pre><code class="language-bash" data-lang="bash"><span class="nb">cd </span>Efficient_ACL_via_RCS/ACL_RCS/ImageNet_32
<span class="nv">PRE_TRAIN_DIR</span><span class="o">=</span>ACL_RCS_WRN_ImageNet
<span class="nv">FINETUNE_DIR</span><span class="o">=</span>ACL_RCS_WRN_ImageNet_cifar10
<span class="c"># Fine-tuning stage (SLF)</span>
python transfer.py <span class="nt">--out_dir</span> <span class="nv">$FINETUNE_DIR</span>/SLF <span class="se">\</span>
                   <span class="nt">--resume</span> <span class="nv">$PRE_TRAIN_DIR</span>/model.pt 
                   <span class="nt">--dataset</span> cifar10 <span class="se">\</span>
                   <span class="nt">--lr</span> 0.01 <span class="nt">--linear</span> 
<span class="c"># Fine-tuning stage (ALF)</span>
python adv_tune.py <span class="nt">--out_dir</span> <span class="nv">$FINETUNE_DIR</span>/ALF <span class="se">\</span>
                   <span class="nt">--resume</span> <span class="nv">$PRE_TRAIN_DIR</span>/model.pt <span class="se">\</span>
                   <span class="nt">--dataset</span> cifar10 <span class="se">\</span>
                   <span class="nt">--lr</span> 0.1 <span class="nt">--linear</span> 
<span class="c"># Fine-tuning stage (AFF)</span>
python adv_tune.py <span class="nt">--out_dir</span> <span class="nv">$FINETUNE_DIR</span>/AFF <span class="se">\</span>
                   <span class="nt">--resume</span> <span class="nv">$PRE_TRAIN_DIR</span>/model.pt <span class="se">\</span>
                   <span class="nt">--dataset</span> cifar10 <span class="se">\</span>
                   <span class="nt">--lr</span> 0.1</code></pre></figure> <p><strong>RCS can speed up Standard Adversarial Training (SAT) <d-cite key="PGD"></d-cite> on ImageNet-1K.</strong> The results show that RCS is applicable to robust pre-training in the supervised setting.</p> <div class="row mt-3"> <div class="col-sm mt-3 mt-md-0"> <figure> <picture> <source class="responsive-img-srcset" media="(max-width: 480px)" srcset="/2024/assets/img/2024-05-07-robust-foundation-model/RCS_exp3-480.webp"></source> <source class="responsive-img-srcset" media="(max-width: 800px)" srcset="/2024/assets/img/2024-05-07-robust-foundation-model/RCS_exp3-800.webp"></source> <source class="responsive-img-srcset" media="(max-width: 1400px)" srcset="/2024/assets/img/2024-05-07-robust-foundation-model/RCS_exp3-1400.webp"></source> <img src="/2024/assets/img/2024-05-07-robust-foundation-model/RCS_exp3.png" class="img-fluid" width="auto" height="auto" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"> </picture> </figure> </div> </div> <p>To reproduce the above results of the robustness transferability from ImageNet-1K to CIFAR-10, you can use the following scripts.</p> <ul> <li>At the pre-training stage, you can conduct SAT using WRN-28-10 on ImageNet-1K of \(32 \times 32\) resolution.</li> </ul> <figure class="highlight"><pre><code class="language-bash" data-lang="bash">git clone https://github.com/GodXuxilie/Efficient_ACL_via_RCS.git
<span class="nb">cd </span>Efficient_ACL_via_RCS/SAT_RCS/ImageNet_32
<span class="c"># Pre-training stage using RCS</span>
<span class="nv">PRE_TRAIN_DIR</span><span class="o">=</span>SAT_RCS_WRN_ImageNet
<span class="nb">nohup </span>python SAT_RCS.py <span class="nt">--gpu</span> 0,1,2,3 <span class="nt">--out_dir</span> <span class="nv">$PRE_TRAIN_DIR</span> <span class="nt">--fraction</span> 0.2</code></pre></figure> <ul> <li>At the fine-tuning stage, you can fine-tune ImageNet-1K pre-trained WRN-28-10 on CIFAR-10.</li> </ul> <figure class="highlight"><pre><code class="language-bash" data-lang="bash"><span class="nb">cd </span>Efficient_ACL_via_RCS/SAT_RCS/ImageNet_32
<span class="nv">PRE_TRAIN_DIR</span><span class="o">=</span>SAT_RCS_WRN_ImageNet
<span class="nv">FINETUNE_DIR</span><span class="o">=</span>SAT_RCS_WRN_ImageNet_cifar10
<span class="c"># Fine-tuning stage (ALF)</span>
python adv_tune.py <span class="nt">--out_dir</span> <span class="nv">$FINETUNE_DIR</span>/ALF <span class="se">\</span>
                   <span class="nt">--resume</span> <span class="nv">$PRE_TRAIN_DIR</span>/checkpoint.pth.tar <span class="se">\</span>
                   <span class="nt">--dataset</span> cifar10 <span class="se">\</span>
                   <span class="nt">--lr</span> 0.1 <span class="se">\</span>
                   <span class="nt">--linear</span> 
<span class="c"># Fine-tuning stage (AFF)</span>
python adv_tune.py <span class="nt">--out_dir</span> <span class="nv">$FINETUNE_DIR</span>/AFF <span class="se">\</span>
                   <span class="nt">--resume</span> <span class="nv">$PRE_TRAIN_DIR</span>/checkpoint.pth.tar 
                   <span class="nt">--dataset</span> cifar10 <span class="se">\</span>
                   <span class="nt">--lr</span> 0.1</code></pre></figure> </d-article> <d-appendix> <d-footnote-list></d-footnote-list> <d-citation-list></d-citation-list> </d-appendix> </div> <d-bibliography src="/2024/assets/bibliography/2024-05-07-robust-foundation-model.bib"></d-bibliography> <d-article id="bibtex-container" class="related highlight"> For attribution in academic contexts, please cite this work as <pre id="bibtex-academic-attribution">
        PLACEHOLDER FOR ACADEMIC ATTRIBUTION
  </pre> BibTeX citation <pre id="bibtex-box">
        PLACEHOLDER FOR BIBTEX
  </pre> </d-article> <script src="https://utteranc.es/client.js" repo="iclr-blogposts/2024" issue-term="pathname" theme="github-light" crossorigin="anonymous" async> </script> <script src="https://cdn.jsdelivr.net/npm/bootstrap@4.6.1/dist/js/bootstrap.bundle.min.js" integrity="sha256-fgLAgv7fyCGopR/gBNq2iW3ZKIdqIcyshnUULC4vex8=" crossorigin="anonymous"></script> <script src="https://cdn.jsdelivr.net/npm/mdbootstrap@4.20.0/js/mdb.min.js" integrity="sha256-NdbiivsvWt7VYCt6hYNT3h/th9vSTL4EDWeGs5SN3DA=" crossorigin="anonymous"></script> </body> </html>