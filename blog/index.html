<!DOCTYPE html> <html lang="en"> <head> <meta charset="utf-8"> <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no"> <meta http-equiv="X-UA-Compatible" content="IE=edge"> <title> blog | ICLR Blogposts 2024</title> <meta name="author" content="ICLR Blog"/> <meta name="description" content="Home to the 2024 ICLR Blogposts track "/> <meta name="keywords" content="machine-learning, ml, deep-learning, reinforcement-learning, iclr"/> <link href="https://cdn.jsdelivr.net/npm/bootstrap@4.6.1/dist/css/bootstrap.min.css" rel="stylesheet" integrity="sha256-DF7Zhf293AJxJNTmh5zhoYYIMs2oXitRfBjY+9L//AY=" crossorigin="anonymous"> <link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/mdbootstrap@4.20.0/css/mdb.min.css" integrity="sha256-jpjYvU3G3N6nrrBwXJoVEYI/0zw8htfFnhT9ljN3JJw=" crossorigin="anonymous"/> <link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/@fortawesome/fontawesome-free@5.15.4/css/all.min.css" integrity="sha256-mUZM63G8m73Mcidfrv5E+Y61y7a12O5mW4ezU3bxqW4=" crossorigin="anonymous"> <link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/academicons@1.9.1/css/academicons.min.css" integrity="sha256-i1+4qU2G2860dGGIOJscdC30s9beBXjFfzjWLjBRsBg=" crossorigin="anonymous"> <link rel="stylesheet" type="text/css" href="https://fonts.googleapis.com/css?family=Roboto:300,400,500,700|Roboto+Slab:100,300,400,500,700|Material+Icons"> <link rel="stylesheet" href="https://cdn.jsdelivr.net/gh/jwarby/jekyll-pygments-themes@master/github.css" media="" id="highlight_theme_light"/> <link rel="shortcut icon" href="/2024/assets/img/iclr_favicon.ico"/> <link rel="stylesheet" href="/2024/assets/css/main.css"> <link rel="canonical" href="https://iclr-blogposts.github.io/2024/blog/"> <link rel="stylesheet" href="https://cdn.jsdelivr.net/gh/jwarby/jekyll-pygments-themes@master/native.css" media="none" id="highlight_theme_dark"/> <script src="/2024/assets/js/theme.js"></script> <script src="/2024/assets/js/dark_mode.js"></script> </head> <body class="fixed-top-nav "> <header> <nav id="navbar" class="navbar navbar-light navbar-expand-sm fixed-top"> <div class="container"> <a class="navbar-brand title font-weight-lighter" href="/2024/">ICLR Blogposts 2024</a> <button class="navbar-toggler collapsed ml-auto" type="button" data-toggle="collapse" data-target="#navbarNav" aria-controls="navbarNav" aria-expanded="false" aria-label="Toggle navigation"> <span class="sr-only">Toggle navigation</span> <span class="icon-bar top-bar"></span> <span class="icon-bar middle-bar"></span> <span class="icon-bar bottom-bar"></span> </button> <div class="collapse navbar-collapse text-right" id="navbarNav"> <ul class="navbar-nav ml-auto flex-nowrap"> <li class="nav-item "> <a class="nav-link" href="/2024/about/">about</a> </li> <li class="nav-item "> <a class="nav-link" href="/2024/call/">call for blogposts</a> </li> <li class="nav-item "> <a class="nav-link" href="/2024/submitting/">submitting</a> </li> <li class="nav-item "> <a class="nav-link" href="/2024/reviewing/">reviewing</a> </li> <li class="nav-item active"> <a class="nav-link" href="/2024/blog/index.html">blog<span class="sr-only">(current)</span></a> </li> <li class="nav-item dropdown "> <a class="nav-link dropdown-toggle" href="#" id="navbarDropdown" role="button" data-toggle="dropdown" aria-haspopup="true" aria-expanded="false">other iterations</a> <div class="dropdown-menu dropdown-menu-right" aria-labelledby="navbarDropdown"> <a class="dropdown-item" href="https://iclr-blogposts.github.io/2025/">2025</a> <div class="dropdown-divider"></div> <a class="dropdown-item" href="https://iclr-blogposts.github.io/2024/"><strong>2024</strong></a> <div class="dropdown-divider"></div> <a class="dropdown-item" href="https://iclr-blogposts.github.io/2023/">2023</a> <div class="dropdown-divider"></div> <a class="dropdown-item" href="https://iclr-blog-track.github.io/home/" target="_blank" rel="noopener noreferrer">2022</a> </div> </li> <li class="toggle-container"> <button id="light-toggle" title="Change theme"> <i class="fas fa-moon"></i> <i class="fas fa-sun"></i> </button> </li> </ul> </div> </div> </nav> </header> <div class="header-background"><div class="img"></div></div> <div class="container mt-5"> <div class="post"> <div class="header-bar"> <h1>blogposts</h1> <h2>Blog Posts</h2> </div> <ul class="post-list"> <li> <h3> <a class="post-title" href="/2024/blog/language-model-development-as-a-new-subfield/">A New Alchemy: Language Model Development as a Subfield?</a> </h3> <p>This blog post makes the case that the body of research on language models become sufficiently large and mature that we can start thinking about “language model development” as a new subfield. To support this claim, we sketch out the focuses and methodologies of this new subfield. In addition, we provide some personal reflections on what to do when your field of study gives birth to a new one.</p> <p class="post-meta"> 12 min read   ·   May 7, 2024 </p> <p class="post-tags"> <a href="/2024/blog/2024"> <i class="fas fa-calendar fa-sm"></i> 2024 </a> </p> </li> <li> <h3> <a class="post-title" href="/2024/blog/mode-switching/">Behavioral Differences in Mode-Switching Exploration for Reinforcement Learning</a> </h3> <p>In 2022, researchers from Google DeepMind presented an initial study on mode-switching exploration, by which an agent separates its exploitation and exploration actions more coarsely throughout an episode by intermittently and significantly changing its behavior policy. We supplement their work in this blog post by showcasing some observed behavioral differences between mode-switching and monolithic exploration on the Atari suite and presenting illustrative examples of its benefits. This work aids practitioners and researchers by providing practical guidance and eliciting future research directions in mode-switching exploration.</p> <p class="post-meta"> 32 min read   ·   May 7, 2024 </p> <p class="post-tags"> <a href="/2024/blog/2024"> <i class="fas fa-calendar fa-sm"></i> 2024 </a> </p> </li> <li> <h3> <a class="post-title" href="/2024/blog/dpi-fsvi/">Bridging the Data Processing Inequality and Function-Space Variational Inference</a> </h3> <p>This blog post explores the interplay between the <i>Data Processing Inequality (DPI)</i>, a cornerstone concept in information theory, and <i>Function-Space Variational Inference (FSVI)</i> within the context of Bayesian deep learning. The DPI governs the transformation and flow of information through stochastic processes, and its unique connection to FSVI is employed to highlight FSVI's focus on Bayesian predictive posteriors over parameter space. The post examines various forms of the DPI, including the KL divergence based DPI, and provides intuitive examples and detailed proofs. It also explores the equality case of the DPI to gain a deeper understanding. The connection between DPI and FSVI is then established, showing how FSVI can measure a predictive divergence independent of parameter symmetries. The post relates FSVI to knowledge distillation and label entropy regularization, highlighting the practical relevance of the theoretical concepts. Throughout the post, theoretical concepts are intertwined with intuitive explanations and mathematical rigor, offering a comprehensive understanding of these complex topics. By examining these concepts in depth, the post provides valuable insights for both theory and practice in machine learning.</p> <p class="post-meta"> 53 min read   ·   May 7, 2024 </p> <p class="post-tags"> <a href="/2024/blog/2024"> <i class="fas fa-calendar fa-sm"></i> 2024 </a>   ·   <a href="/2024/blog/category/data-processing-inequality"> <i class="fas fa-tag fa-sm"></i> Data Processing Inequality</a>   <a href="/2024/blog/category/information-theory"> <i class="fas fa-tag fa-sm"></i> Information Theory</a>   <a href="/2024/blog/category/function-space-variational-inference"> <i class="fas fa-tag fa-sm"></i> Function-Space Variational Inference</a>   <a href="/2024/blog/category/parameter-equivalence-classes"> <i class="fas fa-tag fa-sm"></i> Parameter Equivalence Classes</a>   <a href="/2024/blog/category/entropy-regularization"> <i class="fas fa-tag fa-sm"></i> Entropy Regularization</a>   <a href="/2024/blog/category/label-entropy-regularization"> <i class="fas fa-tag fa-sm"></i> Label Entropy Regularization</a>   </p> </li> <li> <h3> <a class="post-title" href="/2024/blog/diffusion-theory-from-scratch/">Building Diffusion Model's theory from ground up</a> </h3> <p>Diffusion Models, a new generative model family, have taken the world by storm after the seminal paper by Ho et al. [2020]. While diffusion models are often described as a probabilistic Markov Chains, their underlying principle is based on the decade-old theory of Stochastic Differential Equations (SDE), as found out later by Song et al. [2021]. In this article, we will go back and revisit the 'fundamental ingredients' behind the SDE formulation and show how the idea can be 'shaped' to get to the modern form of Score-based Diffusion Models. We'll start from the very definition of the 'score', how it was used in the context of generative modeling, how we achieve the necessary theoretical guarantees and how the critical design choices were made to finally arrive at the more 'principled' framework of Score-based Diffusion. Throughout this article, we provide several intuitive illustrations for ease of understanding.</p> <p class="post-meta"> 34 min read   ·   May 7, 2024 </p> <p class="post-tags"> <a href="/2024/blog/2024"> <i class="fas fa-calendar fa-sm"></i> 2024 </a> </p> </li> <li> <h3> <a class="post-title" href="/2024/blog/deqalg-reasoning/">Deep Equilibrium Models For Algorithmic Reasoning</a> </h3> <p>In this blogpost we discuss the idea of teaching neural networks to reach fixed points when reasoning. Specifically, on the algorithmic reasoning benchmark CLRS the current neural networks are told the number of reasoning steps they need, which they shouldn't be given. While a quick fix is to add a termination network that predicts when to stop, a much more salient inductive bias is that the neural network shouldn't change its answer any further once the answer is correct, i.e. it should reach a fixed point. This is supported by denotational semantics, which tells us that while loops that terminate are the minimum fixed points of a function. We implement this idea with the help of deep equilibrium models and discuss several hurdles one encounters along the way. We show on several algorithms from the CLRS benchmark the partial success of this approach and the difficulty in making it work robustly across all algorithms.</p> <p class="post-meta"> 15 min read   ·   May 7, 2024 </p> <p class="post-tags"> <a href="/2024/blog/2024"> <i class="fas fa-calendar fa-sm"></i> 2024 </a> </p> </li> <li> <h3> <a class="post-title" href="/2024/blog/double-descent-demystified/">Double Descent Demystified</a> </h3> <p>Identifying, Interpreting &amp; Ablating the Sources of a Deep Learning Puzzle</p> <p class="post-meta"> 33 min read   ·   May 7, 2024 </p> <p class="post-tags"> <a href="/2024/blog/2024"> <i class="fas fa-calendar fa-sm"></i> 2024 </a> </p> </li> <li> <h3> <a class="post-title" href="/2024/blog/elaborating-on-the-value-of-flow-matching-for-density-estimation/">Elaborating on the Value of Flow Matching for Density Estimation</a> </h3> <p>The transfer of matching-based training from Diffusion Models to Normalizing Flows allows to fit expressive continuous normalizing flows efficiently and therefore enables their usage for different kinds of density estimation tasks. One particularly interesting task is Simulation-Based Inference, where Flow Matching enabled several improvements. The post shall focus on the discussion of Flow Matching for Continuous Normalizing Flows. To highlight the relevance and the practicality of the method, their use and advantages for Simulation-Based Inference is elaborated.</p> <p class="post-meta"> 21 min read   ·   May 7, 2024 </p> <p class="post-tags"> <a href="/2024/blog/2024"> <i class="fas fa-calendar fa-sm"></i> 2024 </a> </p> </li> <li> <h3> <a class="post-title" href="/2024/blog/exploring-meta-learned-curiosity-algorithms/">Exploring Meta-learned Curiosity Algorithms</a> </h3> <p>This blog post delves into Alet et al.'s ICLR 2020 paper, Meta-learning curiosity algorithms, which introduces a unique approach to meta-learning curiosity algorithms. Instead of meta-learning neural network weights, the focus is on meta-learning pieces of code, allowing it to be interpretable by humans. The post explores the two meta-learned algorithms, namely Fast Action Space Transition (FAST) and Cycle-Consistency Intrinsic Motivation (CCIM).</p> <p class="post-meta"> 41 min read   ·   May 7, 2024 </p> <p class="post-tags"> <a href="/2024/blog/2024"> <i class="fas fa-calendar fa-sm"></i> 2024 </a> </p> </li> <li> <h3> <a class="post-title" href="/2024/blog/update-frequency-in-mbrl/">Fair Model-Based Reinforcement Learning Comparisons with Explicit and Consistent Update Frequency</a> </h3> <p>Implicit update frequencies can introduce ambiguity in the interpretation of model-based reinforcement learning benchmarks, obscuring the real objective of the evaluation. While the update frequency can sometimes be optimized to improve performance, real-world applications often impose constraints, allowing updates only between deployments on the actual system. This blog post emphasizes the need for evaluations using consistent update frequencies across different algorithms to provide researchers and practitioners with clearer comparisons under realistic constraints.</p> <p class="post-meta"> 22 min read   ·   May 7, 2024 </p> <p class="post-tags"> <a href="/2024/blog/2024"> <i class="fas fa-calendar fa-sm"></i> 2024 </a> </p> </li> <li> <h3> <a class="post-title" href="/2024/blog/fairness-ai-two-phil-or-just-one/">Fairness in AI: two philosophies or just one?</a> </h3> <p>The topic of fairness in AI has garnered more attention over the last year, recently with the arrival of the EU's AI Act. This goal of achieving fairness in AI is often done in one of two ways, namely through counterfactual fairness or through group fairness. These research strands originate from two vastly differing ideologies. However, with the use of causal graphs, it is possible to show that they are related and even that satisfying a fairness group measure means satisfying counterfactual fairness.</p> <p class="post-meta"> 18 min read   ·   May 7, 2024 </p> <p class="post-tags"> <a href="/2024/blog/2024"> <i class="fas fa-calendar fa-sm"></i> 2024 </a> </p> </li> <li> <h3> <a class="post-title" href="/2024/blog/bench-hvp/">How to compute Hessian-vector products?</a> </h3> <p>The product between the Hessian of a function and a vector, the Hessian-vector product (HVP), is a fundamental quantity to study the variation of a function. It is ubiquitous in traditional optimization and machine learning. However, the computation of HVPs is often considered prohibitive in the context of deep learning, driving practitioners to use proxy quantities to evaluate the loss geometry. Standard automatic differentiation theory predicts that the computational complexity of an HVP is of the same order of magnitude as the complexity of computing a gradient. The goal of this blog post is to provide a practical counterpart to this theoretical result, showing that modern automatic differentiation frameworks, JAX and PyTorch, allow for efficient computation of these HVPs in standard deep learning cost functions.</p> <p class="post-meta"> 32 min read   ·   May 7, 2024 </p> <p class="post-tags"> <a href="/2024/blog/2024"> <i class="fas fa-calendar fa-sm"></i> 2024 </a> </p> </li> <li> <h3> <a class="post-title" href="/2024/blog/primacy-bias-and-why-it-helps-to-forget/">It's Time to Move On: Primacy Bias and Why It Helps to Forget</a> </h3> <p>'The Primacy Bias in Deep Reinforcement Learning' demonstrates how the first experiences of a deep learning model can cause catastrophic memorization and how this can be prevented. In this post we describe primacy bias, summarize the authors' key findings, and present a simple environment to experiment with primacy bias.</p> <p class="post-meta"> 22 min read   ·   May 7, 2024 </p> <p class="post-tags"> <a href="/2024/blog/2024"> <i class="fas fa-calendar fa-sm"></i> 2024 </a> </p> </li> </ul> <nav aria-label="Blog page naviation"> <ul class="pagination pagination-lg justify-content-center"> <li class="page-item disabled"> <a class="page-link" href="" tabindex="-1" aria-disabled="">Newer</a> </li> <li class="page-item active"><a class="page-link" href="/2024/blog/index.html" title="blog">1</a></li> <li class="page-item "><a class="page-link" href="/2024/blog/page/2/index.html" title="blog - page 2">2</a></li> <li class="page-item "> <a class="page-link" href="/2024/blog/page/2/">Older</a> </li> </ul> </nav> </div> </div> <script src="https://cdn.jsdelivr.net/npm/jquery@3.6.0/dist/jquery.min.js" integrity="sha256-/xUj+3OJU5yExlq6GSYGSHk7tPXikynS7ogEvDej/m4=" crossorigin="anonymous"></script> <script src="https://cdn.jsdelivr.net/npm/bootstrap@4.6.1/dist/js/bootstrap.bundle.min.js" integrity="sha256-fgLAgv7fyCGopR/gBNq2iW3ZKIdqIcyshnUULC4vex8=" crossorigin="anonymous"></script> <script src="https://cdn.jsdelivr.net/npm/mdbootstrap@4.20.0/js/mdb.min.js" integrity="sha256-NdbiivsvWt7VYCt6hYNT3h/th9vSTL4EDWeGs5SN3DA=" crossorigin="anonymous"></script> <script defer src="https://cdn.jsdelivr.net/npm/masonry-layout@4.2.2/dist/masonry.pkgd.min.js" integrity="sha256-Nn1q/fx0H7SNLZMQ5Hw5JLaTRZp0yILA/FRexe19VdI=" crossorigin="anonymous"></script> <script defer src="https://cdn.jsdelivr.net/npm/imagesloaded@4/imagesloaded.pkgd.min.js"></script> <script defer src="/2024/assets/js/masonry.js" type="text/javascript"></script> <script defer src="https://cdn.jsdelivr.net/npm/medium-zoom@1.0.6/dist/medium-zoom.min.js" integrity="sha256-EdPgYcPk/IIrw7FYeuJQexva49pVRZNmt3LculEr7zM=" crossorigin="anonymous"></script> <script defer src="/2024/assets/js/zoom.js"></script> <script defer src="/2024/assets/js/common.js"></script> <script type="text/javascript">window.MathJax={tex:{tags:"ams"}};</script> <script defer type="text/javascript" id="MathJax-script" src="https://cdn.jsdelivr.net/npm/mathjax@3.2.0/es5/tex-mml-chtml.js"></script> <script defer src="https://polyfill.io/v3/polyfill.min.js?features=es6"></script> </body> </html>