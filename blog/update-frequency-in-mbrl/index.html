<!DOCTYPE html> <html> <script>let thunk=()=>{let e=e=>e.trim(),t=e=>e.innerText,n=e=>{let t=e.split(" "),n=t.slice(0,-1).join(" ");return[t.at(-1),n]},i=Array.from(document.getElementsByClassName("author")).map(t).map(e).map(n),a=i[0][0],o=(Array.from(document.getElementsByClassName("affiliation")).filter(e=>"P"===e.nodeName).map(t).map(e),"May 7, 2024"),r="Fair Model-Based Reinforcement Learning Comparisons with Explicit and Consistent Update Frequency",s="Implicit update frequencies can introduce ambiguity in the interpretation of model-based reinforcement learning benchmarks, obscuring the real objective of the evaluation. While the update frequency can sometimes be optimized to improve performance, real-world applications often impose constraints, allowing updates only between deployments on the actual system. This blog post emphasizes the need for evaluations using consistent update frequencies across different algorithms to provide researchers and practitioners with clearer comparisons under realistic constraints.";{let e=i.map(e=>`${e[0]}, ${e[1]}`).join(" and "),t=`\n@inproceedings{${(a+"2024"+r.split(" ").slice(0,3).join("")).replace(" ","").replace(/[\p{P}$+<=>^`|~]/gu,"").toLowerCase().trim()},\n  author = {${e}},\n  title = {${r}},\n  abstract = {${s}},\n  booktitle = {ICLR Blogposts 2024},\n  year = {2024},\n  date = {${o}},\n  note = {${window.location.href}},\n  url  = {${window.location.href}}\n}\n  `.trim();document.getElementById("bibtex-box").innerText=t}{let e=i.map(e=>e[0]),t=`\n${e=e.length>2?e[0]+", et al.":2==e.length?e[0]+" & "+e[1]:e[0]}, "${r}", ICLR Blogposts, 2024.\n`.trim();document.getElementById("bibtex-academic-attribution").innerText=t}};document.addEventListener("readystatechange",function(){"complete"===document.readyState&&thunk()});</script> <head> <meta charset="utf-8"> <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no"> <meta http-equiv="X-UA-Compatible" content="IE=edge"> <title>Fair Model-Based Reinforcement Learning Comparisons with Explicit and Consistent Update Frequency | ICLR Blogposts 2024</title> <meta name="author" content="ICLR Blog"/> <meta name="description" content="Implicit update frequencies can introduce ambiguity in the interpretation of model-based reinforcement learning benchmarks, obscuring the real objective of the evaluation. While the update frequency can sometimes be optimized to improve performance, real-world applications often impose constraints, allowing updates only between deployments on the actual system. This blog post emphasizes the need for evaluations using consistent update frequencies across different algorithms to provide researchers and practitioners with clearer comparisons under realistic constraints."/> <meta name="keywords" content="machine-learning, ml, deep-learning, reinforcement-learning, iclr"/> <link href="https://cdn.jsdelivr.net/npm/bootstrap@4.6.1/dist/css/bootstrap.min.css" rel="stylesheet" integrity="sha256-DF7Zhf293AJxJNTmh5zhoYYIMs2oXitRfBjY+9L//AY=" crossorigin="anonymous"> <link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/mdbootstrap@4.20.0/css/mdb.min.css" integrity="sha256-jpjYvU3G3N6nrrBwXJoVEYI/0zw8htfFnhT9ljN3JJw=" crossorigin="anonymous"/> <link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/@fortawesome/fontawesome-free@5.15.4/css/all.min.css" integrity="sha256-mUZM63G8m73Mcidfrv5E+Y61y7a12O5mW4ezU3bxqW4=" crossorigin="anonymous"> <link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/academicons@1.9.1/css/academicons.min.css" integrity="sha256-i1+4qU2G2860dGGIOJscdC30s9beBXjFfzjWLjBRsBg=" crossorigin="anonymous"> <link rel="stylesheet" type="text/css" href="https://fonts.googleapis.com/css?family=Roboto:300,400,500,700|Roboto+Slab:100,300,400,500,700|Material+Icons"> <link rel="stylesheet" href="https://cdn.jsdelivr.net/gh/jwarby/jekyll-pygments-themes@master/github.css" media="" id="highlight_theme_light"/> <link rel="shortcut icon" href="/2024/assets/img/iclr_favicon.ico"/> <link rel="stylesheet" href="/2024/assets/css/main.css"> <link rel="canonical" href="https://iclr-blogposts.github.io/2024/blog/update-frequency-in-mbrl/"> <link rel="stylesheet" href="https://cdn.jsdelivr.net/gh/jwarby/jekyll-pygments-themes@master/native.css" media="none" id="highlight_theme_dark"/> <script src="/2024/assets/js/theme.js"></script> <script src="/2024/assets/js/dark_mode.js"></script> <script src="https://cdn.jsdelivr.net/npm/jquery@3.6.0/dist/jquery.min.js" integrity="sha256-/xUj+3OJU5yExlq6GSYGSHk7tPXikynS7ogEvDej/m4=" crossorigin="anonymous"></script> <script type="text/javascript">window.MathJax={tex:{tags:"ams"}};</script> <script defer type="text/javascript" id="MathJax-script" src="https://cdn.jsdelivr.net/npm/mathjax@3.2.0/es5/tex-mml-chtml.js"></script> <script defer src="https://polyfill.io/v3/polyfill.min.js?features=es6"></script> <script src="/2024/assets/js/distillpub/template.v2.js"></script> <script src="/2024/assets/js/distillpub/transforms.v2.js"></script> <script src="/2024/assets/js/distillpub/overrides.js"></script> <style type="text/css">.fake-img{background:#bbb;border:1px solid rgba(0,0,0,0.1);box-shadow:0 0 4px rgba(0,0,0,0.1);margin-bottom:12px}.fake-img p{font-family:monospace;color:white;text-align:left;margin:12px 0;text-align:center;font-size:16px}</style> </head> <d-front-matter> <script async type="text/json">{
      "title": "Fair Model-Based Reinforcement Learning Comparisons with Explicit and Consistent Update Frequency",
      "description": "Implicit update frequencies can introduce ambiguity in the interpretation of model-based reinforcement learning benchmarks, obscuring the real objective of the evaluation. While the update frequency can sometimes be optimized to improve performance, real-world applications often impose constraints, allowing updates only between deployments on the actual system. This blog post emphasizes the need for evaluations using consistent update frequencies across different algorithms to provide researchers and practitioners with clearer comparisons under realistic constraints.",
      "published": "May 7, 2024",
      "authors": [
        {
          "author": "Albert Thomas",
          "authorURL": "https://albertcthomas.github.io/",
          "affiliations": [
            {
              "name": "Huawei Noah's Ark Lab",
              "url": ""
            }
          ]
        },
        {
          "author": "Abdelhakim Benechehab",
          "authorURL": "https://scholar.google.com/citations?user=JxgqOKwAAAAJ",
          "affiliations": [
            {
              "name": "Huawei Noah's Ark Lab - Department of Data Science, EURECOM, France",
              "url": ""
            }
          ]
        },
        {
          "author": "Giuseppe Paolo",
          "authorURL": "https://www.giupaolo.com",
          "affiliations": [
            {
              "name": "Huawei Noah's Ark Lab",
              "url": ""
            }
          ]
        },
        {
          "author": "Balázs Kégl",
          "authorURL": "https://twitter.com/balazskegl",
          "affiliations": [
            {
              "name": "Huawei Noah's Ark Lab",
              "url": ""
            }
          ]
        }
        
      ],
      "katex": {
        "delimiters": [
          {
            "left": "$",
            "right": "$",
            "display": false
          },
          {
            "left": "$$",
            "right": "$$",
            "display": true
          }
        ]
      }
    }</script> </d-front-matter> <body class="fixed-top-nav"> <header> <nav id="navbar" class="navbar navbar-light navbar-expand-sm fixed-top"> <div class="container"> <a class="navbar-brand title font-weight-lighter" href="/2024/">ICLR Blogposts 2024</a> <button class="navbar-toggler collapsed ml-auto" type="button" data-toggle="collapse" data-target="#navbarNav" aria-controls="navbarNav" aria-expanded="false" aria-label="Toggle navigation"> <span class="sr-only">Toggle navigation</span> <span class="icon-bar top-bar"></span> <span class="icon-bar middle-bar"></span> <span class="icon-bar bottom-bar"></span> </button> <div class="collapse navbar-collapse text-right" id="navbarNav"> <ul class="navbar-nav ml-auto flex-nowrap"> <li class="nav-item "> <a class="nav-link" href="/2024/about/">about</a> </li> <li class="nav-item "> <a class="nav-link" href="/2024/call/">call for blogposts</a> </li> <li class="nav-item "> <a class="nav-link" href="/2024/submitting/">submitting</a> </li> <li class="nav-item "> <a class="nav-link" href="/2024/reviewing/">reviewing</a> </li> <li class="nav-item "> <a class="nav-link" href="/2024/blog/index.html">blog</a> </li> <li class="nav-item dropdown "> <a class="nav-link dropdown-toggle" href="#" id="navbarDropdown" role="button" data-toggle="dropdown" aria-haspopup="true" aria-expanded="false">other iterations</a> <div class="dropdown-menu dropdown-menu-right" aria-labelledby="navbarDropdown"> <a class="dropdown-item" href="https://iclr-blogposts.github.io/2025/">2025</a> <div class="dropdown-divider"></div> <a class="dropdown-item" href="https://iclr-blogposts.github.io/2024/"><strong>2024</strong></a> <div class="dropdown-divider"></div> <a class="dropdown-item" href="https://iclr-blogposts.github.io/2023/">2023</a> <div class="dropdown-divider"></div> <a class="dropdown-item" href="https://iclr-blog-track.github.io/home/" target="_blank" rel="noopener noreferrer">2022</a> </div> </li> <li class="toggle-container"> <button id="light-toggle" title="Change theme"> <i class="fas fa-moon"></i> <i class="fas fa-sun"></i> </button> </li> </ul> </div> </div> </nav> </header> <div class="post distill"> <d-title> <h1>Fair Model-Based Reinforcement Learning Comparisons with Explicit and Consistent Update Frequency</h1> <p>Implicit update frequencies can introduce ambiguity in the interpretation of model-based reinforcement learning benchmarks, obscuring the real objective of the evaluation. While the update frequency can sometimes be optimized to improve performance, real-world applications often impose constraints, allowing updates only between deployments on the actual system. This blog post emphasizes the need for evaluations using consistent update frequencies across different algorithms to provide researchers and practitioners with clearer comparisons under realistic constraints.</p> </d-title> <d-byline></d-byline> <d-article> <d-contents> <nav class="l-text figcaption"> <h3>Contents</h3> <div><a href="#introduction">Introduction</a></div> <div><a href="#three-popular-model-based-reinforcement-learning-algorithms">Three popular model-based reinforcement learning algorithms</a></div> <ul> <li><a href="#mbpo">MBPO</a></li> <li><a href="#pets">PETS</a></li> <li><a href="#bremen">BREMEN</a></li> </ul> <div><a href="#making-the-update-frequency-more-accessible">Making the update frequency more accessible</a></div> <div><a href="#comparisons-with-fixed-update-frequency">Comparisons with fixed update frequency</a></div> <div><a href="#ablation-studies">Ablation studies</a></div> <ul> <li><a href="#varying-the-update-frequency-in-mbpo">Varying the update frequency in MBPO</a></li> </ul> <div><a href="#conclusion">Conclusion</a></div> <div><a href="#appendix">Appendix</a></div> </nav> </d-contents> <h2 id="introduction">Introduction</h2> <p>In reinforcement learning <d-cite key="Sutton1998"></d-cite>, an agent learns to make decisions by interacting with an environment, receiving a feedback, or reward, following each action it takes to move from a state of the environment to another. The objective is to learn a policy, a mapping from states to action, that maximizes the expected cumulative reward over successive interactions.</p> <p>There are two main approaches when designing a reinforcement learning algorithm: model-based or model-free. Model-based reinforcement learning (MBRL) algorithms <d-cite key="Moerland2021"></d-cite> first learn a model of the environment dynamics which, given a state of the environment and an action, predicts the next state of the environment. This model can then be used in place of the real environment to learn or decide how to act. Model-free algorithms avoid this step and directly try to learn a policy. As MBRL algorithms can rely on the learned dynamics model instead of the real environment, they are known to be more sample efficient than model-free algorithms (see for instance <d-cite key="Chua2018"></d-cite> or <d-cite key="Janner2019"></d-cite>). MBRL is thus a good choice when interactions with the environment are limited, which is often the case for real applications such as controlling engineering systems.</p> <p>We discuss here about one of the design choices of MBRL algorithms: the <em>update frequency</em> of the agent. As shown in the figure below<d-footnote> This figure is inspired by Figure 1 in <d-cite key="Matsushima2021"></d-cite>.</d-footnote>, the frequency at which algorithms update their agent varies widely: some algorithms update their agent after each step on the real system <d-cite key="Janner2019"></d-cite> while others update after thousands of steps <d-cite key="Matsushima2021"></d-cite>. At the end of the spectrum, the pure offline setting considers only a single training of the agent from an initial dataset <d-cite key="Yu2020"></d-cite><d-footnote> We observe that similar differences in update frequency exist in the model-free literature but we decide to focus only on model-based algorithms.</d-footnote>.</p> <figure> <picture> <source class="responsive-img-srcset" media="(max-width: 480px)" srcset="/2024/assets/img/2024-05-07-update-frequency-in-mbrl/bremen-480.webp"></source> <source class="responsive-img-srcset" media="(max-width: 800px)" srcset="/2024/assets/img/2024-05-07-update-frequency-in-mbrl/bremen-800.webp"></source> <source class="responsive-img-srcset" media="(max-width: 1400px)" srcset="/2024/assets/img/2024-05-07-update-frequency-in-mbrl/bremen-1400.webp"></source> <img src="/2024/assets/img/2024-05-07-update-frequency-in-mbrl/bremen.png" class="img-fluid" width="auto" height="auto" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"> </picture> </figure> <p>The update frequency is often viewed as yet another hyperparameter of the complex MBRL pipeline. However, in practice the update frequency may be imposed by real-life deployment constraints, motivating the discussions of this blog post. It is often the case that for safety reasons, system engineers agree to run a new agent on their system for a given period of time but prefer the agent to be fixed during this deployment, as <d-cite key="Matsushima2021"></d-cite> studies. System engineers are then able to investigate the fixed solution before deciding to deploy it, knowing that it will not change during the deployment. It also happens that the system on which the agent is deployed does not have the required computational resources to support agent updates. Such real-life constraints could thus discard state-of-the-art MBRL algorithms that require updating their agent too frequently to perform well.</p> <p>Given the importance of the update frequency in real-life applications, this blog post advocates for:</p> <ul> <li>explicitly specifying the update frequency employed by each algorithm in a benchmark, as this remains implicit and hard to find in many existing benchmarks,</li> <li>conducting additional experiments that compare algorithms under a given update frequency, mirroring the constraints often encountered in real-life applications, and</li> <li>performing more ablation studies on update frequency, evaluating its impact on algorithm performance.</li> </ul> <p>For the rest of this blog post, we define a <em>deployment</em> as a data collection campaign realized with a fixed agent. The agents are thus updated between two consecutive deployments but not within one deployment. The <em>update frequency</em> is the number of steps realized at each deployment (that we assume fixed for all deployments). We use the term <em>agent</em> to refer to all the components of the model-based algorithm that are used to act on the system. For instance, in a Dyna-style algorithm <d-cite key="Sutton1991"></d-cite>, where a model-free algorithm is applied on the model instead of the real system, <em>agent</em> would thus refer to both the dynamics model and the policy learned with a model-free algorithm.</p> <p>We begin by introducing three popular MBRL algorithms (MBPO, PETS and BREMEN) as we will often refer to them to illustrate our arguments.</p> <h2 id="three-popular-mbrl-algorithms">Three popular MBRL algorithms</h2> <p>The following table gives an overview of the update frequency of the three algorithms we discussed below and few others. This table is not meant to provide an exhaustive list of all the MBRL algorithms but rather to give an idea of the different training schedules that are used in the literature.</p> <table> <thead> <tr> <th>Algorithm</th> <th>Agent update frequency</th> <th>Policy update frequency</th> <th>Model update frequency</th> </tr> </thead> <tbody> <tr> <td>MBPO <d-cite key="Janner2019"></d-cite> </td> <td>1 step</td> <td>1 step</td> <td>250 steps</td> </tr> <tr> <td>PETS <d-cite key="Chua2018"></d-cite> </td> <td>Task Horizon</td> <td>No policy</td> <td>Task Horizon</td> </tr> <tr> <td>PILCO <d-cite key="Deisenroth2011"></d-cite> </td> <td>Task Horizon</td> <td>Task Horizon</td> <td>Task Horizon</td> </tr> <tr> <td>BREMEN <d-cite key="Matsushima2021"></d-cite> </td> <td>100k or 200k steps</td> <td>100k or 200k steps</td> <td>100k or 200k steps</td> </tr> <tr> <td>ME-TRPO <d-cite key="Kurutach2018"></d-cite> </td> <td>3k or 6k steps</td> <td>3k or 6k steps</td> <td>3k or 6k steps</td> </tr> </tbody> </table> <h3 id="mbpo">MBPO</h3> <p>Model-based Policy Optimization (MBPO) <d-cite key="Janner2019"></d-cite> <d-footnote>Original code available at https://github.com/jannerm/mbpo</d-footnote> is one of the most well-known model-based algorithms. The algorithm trains an ensemble of probabilistic neural networks for the dynamics model <d-cite key="Chua2018"></d-cite> and trains a model-free agent, Soft Actor Critic (SAC) <d-cite key="Haarnoja2018"></d-cite>, using short rollouts on the model to avoid error accumulation. The agent is updated at each step: the model is updated each 250 steps but the SAC policy is updated at each step. This highly frequent update schedule discards MBPO even for small deployments on real systems.</p> <h3 id="pets">PETS</h3> <p>Probabilistic Ensemble and Trajectory Sampling (PETS) <d-cite key="Chua2018"></d-cite> <d-footnote>Original code available at https://github.com/kchua/handful-of-trials</d-footnote> is another popular model-based algorithm known for its use of an ensemble of probabilistic neural networks for the dynamics model (MBPO uses the dynamics model introduced by PETS). PETS relies on the learned model and the Cross-Entropy Method to search for the best action sequence at decision time. Therefore, it does not have to learn (nor update) a policy, as MBPO does with SAC. The only component that needs learning is the dynamics model. Compared to MBPO, the dynamics model is updated at the end of each episode (usually 1000 steps).</p> <h3 id="bremen">BREMEN</h3> <p>Behavior-Regularized Model-ENsemble (BREMEN) <d-cite key="Matsushima2021"></d-cite><d-footnote>Original code available at https://github.com/matsuolab/BREMEN</d-footnote> considers the setting where only a few deployments (between 5 to 10) are possible on the real system. However large datasets can be collected at each deployment (they assume 100 000 or 200 000 transitions for each deployment, far more than just one episode which is usually of the order of 1000 transitions). The algorithm relies on an ensemble of deterministic dynamics models and a policy learned on the model, à la Dyna-Style. It only updates the policy and the model between two consecutive deployments. The update frequency is here very clear as it is motivated by real-life applications where deployments are limited. Therefore in this algorithm this is not an hyperparameter that can be tuned for better performance but rather a parameter imposed by the application. One of the goals of the blog post is to emphasize and to develop the idea of a constrained update frequency.</p> <p>We now detail the main arguments of our blog post: making the update frequency more accessible, designing benchmarks with fixed update frequencies and running ablation studies on the update frequency.</p> <h2 id="making-the-update-frequency-more-accessible">Making the update frequency more accessible</h2> <p>Experiments done in popular papers do not always explicit the update frequencies they use for each of the algorithms they run. When nothing is said, it is very likely that most of the times the benchmarks are using the original implementation of the algorithms, shared by the authors of the algorithms in the best case. For instance the MBPO paper <d-cite key="Janner2019"></d-cite> does not mention the update frequencies that the authors used in their experiments. The update frequency of MBPO can be found in the code shared by the authors. However it is harder to find the update frequency that the authors used for PETS. We thus assume that they use the original PETS update frequency, which updates the agent at the end of each episode. We also looked at one of the most exhaustive benchmark of MBRL algorithms <d-cite key="Wang2019"></d-cite>. Nothing is said in the paper about the update frequency and a careful investigation of the code provided by the authors is required (more on this later).</p> <p>The difficulty in knowing the update frequencies used in benchmarks makes it harder for the researchers and practitioners to take this parameter into account to assess the performance of the algorithms and whether they would be good candidates for their real-life applications. It also demands much more investigation from the reader to know what the authors used.</p> <p>MBRL algorithms have an order of magnitude more meaningful hyperparameters than supervised models, and managing and reporting on them usually falls out of the scope of research papers. The practice of sharing the code alleviates this issue somewhat, and should be saluted, since we can always dig up in the code what the parameters were. However, ideally, choices that drastically change the performance of the algorithms, should be made explicit as much as possible in the research papers and the ablation studies.</p> <h2 id="comparisons-with-fixed-update-frequency">Comparisons with fixed update frequency</h2> <p>We want to make the community aware of the importance of the update frequency when comparing algorithms and when designing benchmarks. Running benchmarks without any constraints allows using different update frequencies for each algorithm. We believe that such benchmarks are valuable for the community. However it would also be very informative for the community to have benchmarks with comparable update frequencies between the algorithms. This would for instance help to find the potentially best algorithms for real applications with constraints on the update frequency.</p> <p>Coming back to the experiments run in MBPO’s paper, as the default MBPO implementation updates the model each 250 steps, it might also make sense to allow PETS to be updated each 250 steps as well to have comparable results. We also note that the MBRL-Lib paper <d-cite key="Pineda2021"></d-cite> compares the MBRL-Lib implementations of PETS and MBPO with their respective original update frequency. We do not think that this would have a big impact for these two algorithms but it would be fairer to use the same update frequency. Finally, looking at the code of the MBRL benchmark done by <d-cite key="Wang2019"></d-cite>, it is not clear whether the same update frequency is used for all the algorithms of the benchmark <d-footnote>For instance it seems the update frequency on Acrobot is 3000 for RS (time_step_per_batch in https://github.com/WilsonWangTHU/mbbl/blob/master/scripts/exp_1_performance_curve/rs.sh) but 5000 for ME-TRPO (num_path_onpol $\times$ env_horizon in https://github.com/WilsonWangTHU/mbbl-metrpo/blob/master/configs/params_acrobot.json).</d-footnote>.</p> <p>The BREMEN paper <d-cite key="Matsushima2021"></d-cite> has a benchmark comparing different algorithms under fixed update frequencies. This gives valuable insights on the performance of the existing algorithms under these deployment constraints. The next step would be to evaluate the performance with a different number of deployments and a different number of steps per deployment, which we now argue for in the next section.</p> <h2 id="ablation-studies">Ablation studies</h2> <p>Comparisons of different update frequencies are very rare in existing benchmarks and existing papers. Even without real-life constraints it would be valuable to know how sensitive the performance of a given algorithm is with respect to the update frequency. The issue for the authors is that this could be asked for many other hyperparameters and represent additional computational budget and time. However we often find ablations on the number of models (if the model is an ensemble), the rollout length, the number of gradient updates for the model-free policy, but very rarely on the update frequency. It is very likely that the agents that are good for small deployments would be bad for large deployments, a setting that would tend to be closer to the pure offline setting (for the same total budget of real system interactions). We perform such an ablation study using MBPO in the next section, showing that MBPO’s performance is degrading with larger update frequencies.</p> <h3 id="varying-the-update-frequency-in-mbpo">Varying the update frequency in MBPO</h3> <p>Using the MBPO implementation and the examples provided by MBRL-Lib <d-cite key="Pineda2021"></d-cite> we ran MBPO on Gym-Halfcheetah-v4, Gym-Hopper-v4 and Gym-Walker2d-v4 <d-cite key="Towers2023"></d-cite> with different update frequencies: updating the agent at each step (default implementation described above), each 1000 steps, each 5000 steps and each 10 000 steps. Each curve shows the mean episode return obtained with at least 10 seeds. We did not run Hopper and Walker with an update frequency of 10 000 steps as the performance obtained with 5000 was already poor. The lightly shaded areas indicate the 95% bootstrap confidence interval.</p> <figure> <picture> <source class="responsive-img-srcset" media="(max-width: 480px)" srcset="/2024/assets/img/2024-05-07-update-frequency-in-mbrl/update_frequency_cheetah-480.webp"></source> <source class="responsive-img-srcset" media="(max-width: 800px)" srcset="/2024/assets/img/2024-05-07-update-frequency-in-mbrl/update_frequency_cheetah-800.webp"></source> <source class="responsive-img-srcset" media="(max-width: 1400px)" srcset="/2024/assets/img/2024-05-07-update-frequency-in-mbrl/update_frequency_cheetah-1400.webp"></source> <img src="/2024/assets/img/2024-05-07-update-frequency-in-mbrl/update_frequency_cheetah.png" class="img-fluid" width="auto" height="auto" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"> </picture> </figure> <figure> <picture> <source class="responsive-img-srcset" media="(max-width: 480px)" srcset="/2024/assets/img/2024-05-07-update-frequency-in-mbrl/update_frequency_hopper-480.webp"></source> <source class="responsive-img-srcset" media="(max-width: 800px)" srcset="/2024/assets/img/2024-05-07-update-frequency-in-mbrl/update_frequency_hopper-800.webp"></source> <source class="responsive-img-srcset" media="(max-width: 1400px)" srcset="/2024/assets/img/2024-05-07-update-frequency-in-mbrl/update_frequency_hopper-1400.webp"></source> <img src="/2024/assets/img/2024-05-07-update-frequency-in-mbrl/update_frequency_hopper.png" class="img-fluid" width="auto" height="auto" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"> </picture> </figure> <figure> <picture> <source class="responsive-img-srcset" media="(max-width: 480px)" srcset="/2024/assets/img/2024-05-07-update-frequency-in-mbrl/update_frequency_walker-480.webp"></source> <source class="responsive-img-srcset" media="(max-width: 800px)" srcset="/2024/assets/img/2024-05-07-update-frequency-in-mbrl/update_frequency_walker-800.webp"></source> <source class="responsive-img-srcset" media="(max-width: 1400px)" srcset="/2024/assets/img/2024-05-07-update-frequency-in-mbrl/update_frequency_walker-1400.webp"></source> <img src="/2024/assets/img/2024-05-07-update-frequency-in-mbrl/update_frequency_walker.png" class="img-fluid" width="auto" height="auto" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"> </picture> </figure> <p>Except for the update frequency of 1000 steps on Halfcheetah and Walker which achieves similar performance than the default configuration updating the agent at each step, the results indicate a decline in asymptotic performance with larger update frequencies. Although MBPO exhibits good performance over different environments for the default update frequency, this is not the case for the other update frequencies that we consider here. We note here that 1000 steps is the usual maximum episode length and therefore a reasonable value to try for the update frequency. One insight from this experiment is that even though MBPO is one of the state-of-the-art MBRL algorithms, practical constraints like the update frequency can potentially alleviate its performance in real-world applications.</p> <p>When trying these values of updates frequencies we adjusted the number of gradient steps to maintain a constant ratio of gradient steps per step on the real system. For the maximum buffer size of SAC we used the rule provided in MBPO’s code. The table below shows the values obtained for the maximum buffer size. As shown in the figure below, using a smaller buffer size negatively impacts the performance for the update frequency of 1000 steps and 10 000 steps. While there is a possibility that better values for the hyperparameters (other than the update frequency) could be found, we did what appeared to be the natural way to adapt the other hyperparameters when increasing the update frequency. See the Appendix for the complete description of the hyperparameters used in these experiments.</p> <table> <thead> <tr> <th>Agent update frequency</th> <th>Model update frequency</th> <th>Policy update frequency</th> <th>Max SAC buffer size</th> </tr> </thead> <tbody> <tr> <td>default (1 step)</td> <td>250</td> <td>1</td> <td>400 000</td> </tr> <tr> <td>1 000 steps</td> <td>1000</td> <td>1000</td> <td>400 000</td> </tr> <tr> <td>5 000 steps</td> <td>5000</td> <td>5000</td> <td>2 million</td> </tr> <tr> <td>10 000 steps</td> <td>10 000</td> <td>10 000</td> <td>4 million</td> </tr> </tbody> </table> <figure> <picture> <source class="responsive-img-srcset" media="(max-width: 480px)" srcset="/2024/assets/img/2024-05-07-update-frequency-in-mbrl/buffer_size-480.webp"></source> <source class="responsive-img-srcset" media="(max-width: 800px)" srcset="/2024/assets/img/2024-05-07-update-frequency-in-mbrl/buffer_size-800.webp"></source> <source class="responsive-img-srcset" media="(max-width: 1400px)" srcset="/2024/assets/img/2024-05-07-update-frequency-in-mbrl/buffer_size-1400.webp"></source> <img src="/2024/assets/img/2024-05-07-update-frequency-in-mbrl/buffer_size.png" class="img-fluid" width="auto" height="auto" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"> </picture> </figure> <h2 id="conclusion">Conclusion</h2> <p>The goal of this blog post is to shed light on a frequently overlooked hyperparameter in MBRL: the update frequency. Despite its importance for real-life applications, this parameter is rarely discussed or analyzed. We emphasize the importance of running more evaluations using consistent update frequencies across different algorithms and more ablation studies. We for instance show how the update frequency impacts the performance of MBPO. Similar to the update frequency, we can identify several other hyperparameters that deserve more attention when benchmarking different MBRL algorithms. A typical example is the continual training (of the model and/or policy) versus retraining from scratch (referred to as the primacy bias in some previous work <d-cite key="Nikishin2022"></d-cite> <d-cite key="Qiao2023"></d-cite>). We believe this blog post offers valuable insights to researchers, providing directions that would be worth investigating to explain the differences between MBRL algorithms and whether these differences really impact the existing comparisons.</p> <h2 id="appendix">Appendix</h2> <p>We provide here the configuration files we used to run the different experiments.</p> <h4 id="halfcheetah">Halfcheetah</h4> <ul> <li>Update frequency of 1000 steps</li> </ul> <div class="language-yaml highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="c1"># @package _group_</span>
<span class="na">env</span><span class="pi">:</span> <span class="s2">"</span><span class="s">gym___HalfCheetah-v4"</span>
<span class="na">term_fn</span><span class="pi">:</span> <span class="s2">"</span><span class="s">no_termination"</span>

<span class="na">num_steps</span><span class="pi">:</span> <span class="m">400000</span>
<span class="na">epoch_length</span><span class="pi">:</span> <span class="m">1000</span>
<span class="na">num_elites</span><span class="pi">:</span> <span class="m">5</span>
<span class="na">patience</span><span class="pi">:</span> <span class="m">5</span>
<span class="na">model_lr</span><span class="pi">:</span> <span class="m">0.001</span>
<span class="na">model_wd</span><span class="pi">:</span> <span class="m">0.00001</span>
<span class="na">model_batch_size</span><span class="pi">:</span> <span class="m">256</span>
<span class="na">validation_ratio</span><span class="pi">:</span> <span class="m">0.2</span>
<span class="na">freq_train_model</span><span class="pi">:</span> <span class="m">1000</span>
<span class="na">effective_model_rollouts_per_step</span><span class="pi">:</span> <span class="m">400</span>
<span class="na">rollout_schedule</span><span class="pi">:</span> <span class="pi">[</span><span class="nv">20</span><span class="pi">,</span> <span class="nv">150</span><span class="pi">,</span> <span class="nv">1</span><span class="pi">,</span> <span class="nv">1</span><span class="pi">]</span>
<span class="na">num_sac_updates_per_step</span><span class="pi">:</span> <span class="m">10000</span>
<span class="na">sac_updates_every_steps</span><span class="pi">:</span> <span class="m">1000</span>
<span class="na">num_epochs_to_retain_sac_buffer</span><span class="pi">:</span> <span class="m">1</span>

<span class="na">sac_gamma</span><span class="pi">:</span> <span class="m">0.99</span>
<span class="na">sac_tau</span><span class="pi">:</span> <span class="m">0.005</span>
<span class="na">sac_alpha</span><span class="pi">:</span> <span class="m">0.2</span>
<span class="na">sac_policy</span><span class="pi">:</span> <span class="s2">"</span><span class="s">Gaussian"</span>
<span class="na">sac_target_update_interval</span><span class="pi">:</span> <span class="m">1</span>
<span class="na">sac_automatic_entropy_tuning</span><span class="pi">:</span> <span class="kc">true</span>
<span class="na">sac_target_entropy</span><span class="pi">:</span> <span class="s">-1</span>
<span class="na">sac_hidden_size</span><span class="pi">:</span> <span class="m">512</span>
<span class="na">sac_lr</span><span class="pi">:</span> <span class="m">0.0003</span>
<span class="na">sac_batch_size</span><span class="pi">:</span> <span class="m">256</span>
</code></pre></div></div> <ul> <li>Update frequency of 5000 steps</li> </ul> <div class="language-yaml highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="c1"># @package _group_</span>
<span class="na">env</span><span class="pi">:</span> <span class="s2">"</span><span class="s">gym___HalfCheetah-v4"</span>
<span class="na">term_fn</span><span class="pi">:</span> <span class="s2">"</span><span class="s">no_termination"</span>

<span class="na">num_steps</span><span class="pi">:</span> <span class="m">400000</span>
<span class="na">epoch_length</span><span class="pi">:</span> <span class="m">5000</span>
<span class="na">num_elites</span><span class="pi">:</span> <span class="m">5</span>
<span class="na">patience</span><span class="pi">:</span> <span class="m">5</span>
<span class="na">model_lr</span><span class="pi">:</span> <span class="m">0.001</span>
<span class="na">model_wd</span><span class="pi">:</span> <span class="m">0.00001</span>
<span class="na">model_batch_size</span><span class="pi">:</span> <span class="m">256</span>
<span class="na">validation_ratio</span><span class="pi">:</span> <span class="m">0.2</span>
<span class="na">freq_train_model</span><span class="pi">:</span> <span class="m">5000</span>
<span class="na">effective_model_rollouts_per_step</span><span class="pi">:</span> <span class="m">400</span>
<span class="na">rollout_schedule</span><span class="pi">:</span> <span class="pi">[</span><span class="nv">20</span><span class="pi">,</span> <span class="nv">150</span><span class="pi">,</span> <span class="nv">1</span><span class="pi">,</span> <span class="nv">1</span><span class="pi">]</span>
<span class="na">num_sac_updates_per_step</span><span class="pi">:</span> <span class="m">50000</span>
<span class="na">sac_updates_every_steps</span><span class="pi">:</span> <span class="m">5000</span>
<span class="na">num_epochs_to_retain_sac_buffer</span><span class="pi">:</span> <span class="m">1</span>

<span class="na">sac_gamma</span><span class="pi">:</span> <span class="m">0.99</span>
<span class="na">sac_tau</span><span class="pi">:</span> <span class="m">0.005</span>
<span class="na">sac_alpha</span><span class="pi">:</span> <span class="m">0.2</span>
<span class="na">sac_policy</span><span class="pi">:</span> <span class="s2">"</span><span class="s">Gaussian"</span>
<span class="na">sac_target_update_interval</span><span class="pi">:</span> <span class="m">1</span>
<span class="na">sac_automatic_entropy_tuning</span><span class="pi">:</span> <span class="kc">true</span>
<span class="na">sac_target_entropy</span><span class="pi">:</span> <span class="s">-1</span>
<span class="na">sac_hidden_size</span><span class="pi">:</span> <span class="m">512</span>
<span class="na">sac_lr</span><span class="pi">:</span> <span class="m">0.0003</span>
<span class="na">sac_batch_size</span><span class="pi">:</span> <span class="m">256</span>
</code></pre></div></div> <ul> <li>Update frequency of 10000 steps</li> </ul> <div class="language-yaml highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="c1"># @package _group_</span>
<span class="na">env</span><span class="pi">:</span> <span class="s2">"</span><span class="s">gym___HalfCheetah-v4"</span>
<span class="na">term_fn</span><span class="pi">:</span> <span class="s2">"</span><span class="s">no_termination"</span>

<span class="na">num_steps</span><span class="pi">:</span> <span class="m">400000</span>
<span class="na">epoch_length</span><span class="pi">:</span> <span class="m">10000</span>
<span class="na">num_elites</span><span class="pi">:</span> <span class="m">5</span>
<span class="na">patience</span><span class="pi">:</span> <span class="m">5</span>
<span class="na">model_lr</span><span class="pi">:</span> <span class="m">0.001</span>
<span class="na">model_wd</span><span class="pi">:</span> <span class="m">0.00001</span>
<span class="na">model_batch_size</span><span class="pi">:</span> <span class="m">256</span>
<span class="na">validation_ratio</span><span class="pi">:</span> <span class="m">0.2</span>
<span class="na">freq_train_model</span><span class="pi">:</span> <span class="m">10000</span>
<span class="na">effective_model_rollouts_per_step</span><span class="pi">:</span> <span class="m">400</span>
<span class="na">rollout_schedule</span><span class="pi">:</span> <span class="pi">[</span><span class="nv">20</span><span class="pi">,</span> <span class="nv">150</span><span class="pi">,</span> <span class="nv">1</span><span class="pi">,</span> <span class="nv">1</span><span class="pi">]</span>
<span class="na">num_sac_updates_per_step</span><span class="pi">:</span> <span class="m">100000</span>
<span class="na">sac_updates_every_steps</span><span class="pi">:</span> <span class="m">10000</span>
<span class="na">num_epochs_to_retain_sac_buffer</span><span class="pi">:</span> <span class="m">1</span>

<span class="na">sac_gamma</span><span class="pi">:</span> <span class="m">0.99</span>
<span class="na">sac_tau</span><span class="pi">:</span> <span class="m">0.005</span>
<span class="na">sac_alpha</span><span class="pi">:</span> <span class="m">0.2</span>
<span class="na">sac_policy</span><span class="pi">:</span> <span class="s2">"</span><span class="s">Gaussian"</span>
<span class="na">sac_target_update_interval</span><span class="pi">:</span> <span class="m">1</span>
<span class="na">sac_automatic_entropy_tuning</span><span class="pi">:</span> <span class="kc">true</span>
<span class="na">sac_target_entropy</span><span class="pi">:</span> <span class="s">-1</span>
<span class="na">sac_hidden_size</span><span class="pi">:</span> <span class="m">512</span>
<span class="na">sac_lr</span><span class="pi">:</span> <span class="m">0.0003</span>
<span class="na">sac_batch_size</span><span class="pi">:</span> <span class="m">256</span>
</code></pre></div></div> <h4 id="hopper">Hopper</h4> <ul> <li>Update frequency of 1000 steps</li> </ul> <div class="language-yaml highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="c1"># @package _group_</span>
<span class="na">env</span><span class="pi">:</span> <span class="s2">"</span><span class="s">gym___Hopper-v4"</span>
<span class="na">term_fn</span><span class="pi">:</span> <span class="s2">"</span><span class="s">hopper"</span>

<span class="na">num_steps</span><span class="pi">:</span> <span class="m">125000</span>
<span class="na">epoch_length</span><span class="pi">:</span> <span class="m">1000</span>
<span class="na">num_elites</span><span class="pi">:</span> <span class="m">5</span>
<span class="na">patience</span><span class="pi">:</span> <span class="m">5</span>
<span class="na">model_lr</span><span class="pi">:</span> <span class="m">0.001</span>
<span class="na">model_wd</span><span class="pi">:</span> <span class="m">0.00001</span>
<span class="na">model_batch_size</span><span class="pi">:</span> <span class="m">256</span>
<span class="na">validation_ratio</span><span class="pi">:</span> <span class="m">0.2</span>
<span class="na">freq_train_model</span><span class="pi">:</span> <span class="m">1000</span>
<span class="na">effective_model_rollouts_per_step</span><span class="pi">:</span> <span class="m">400</span>
<span class="na">rollout_schedule</span><span class="pi">:</span> <span class="pi">[</span><span class="nv">20</span><span class="pi">,</span> <span class="nv">150</span><span class="pi">,</span> <span class="nv">1</span><span class="pi">,</span> <span class="nv">15</span><span class="pi">]</span>
<span class="na">num_sac_updates_per_step</span><span class="pi">:</span> <span class="s">40_000</span>
<span class="na">sac_updates_every_steps</span><span class="pi">:</span> <span class="m">1000</span>
<span class="na">num_epochs_to_retain_sac_buffer</span><span class="pi">:</span> <span class="m">1</span>

<span class="na">sac_gamma</span><span class="pi">:</span> <span class="m">0.99</span>
<span class="na">sac_tau</span><span class="pi">:</span> <span class="m">0.005</span>
<span class="na">sac_alpha</span><span class="pi">:</span> <span class="m">0.2</span>
<span class="na">sac_policy</span><span class="pi">:</span> <span class="s2">"</span><span class="s">Gaussian"</span>
<span class="na">sac_target_update_interval</span><span class="pi">:</span> <span class="m">4</span>
<span class="na">sac_automatic_entropy_tuning</span><span class="pi">:</span> <span class="kc">false</span>
<span class="na">sac_target_entropy</span><span class="pi">:</span> <span class="m">1</span> <span class="c1"># ignored, since entropy tuning is false</span>
<span class="na">sac_hidden_size</span><span class="pi">:</span> <span class="m">512</span>
<span class="na">sac_lr</span><span class="pi">:</span> <span class="m">0.0003</span>
<span class="na">sac_batch_size</span><span class="pi">:</span> <span class="m">256</span>
</code></pre></div></div> <ul> <li>Update frequency of 5000 steps</li> </ul> <div class="language-yaml highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="c1"># @package _group_</span>
<span class="na">env</span><span class="pi">:</span> <span class="s2">"</span><span class="s">gym___Hopper-v4"</span>
<span class="na">term_fn</span><span class="pi">:</span> <span class="s2">"</span><span class="s">hopper"</span>

<span class="na">num_steps</span><span class="pi">:</span> <span class="m">125000</span>
<span class="na">epoch_length</span><span class="pi">:</span> <span class="m">1000</span>
<span class="na">num_elites</span><span class="pi">:</span> <span class="m">5</span>
<span class="na">patience</span><span class="pi">:</span> <span class="m">5</span>
<span class="na">model_lr</span><span class="pi">:</span> <span class="m">0.001</span>
<span class="na">model_wd</span><span class="pi">:</span> <span class="m">0.00001</span>
<span class="na">model_batch_size</span><span class="pi">:</span> <span class="m">256</span>
<span class="na">validation_ratio</span><span class="pi">:</span> <span class="m">0.2</span>
<span class="na">freq_train_model</span><span class="pi">:</span> <span class="m">5000</span>
<span class="na">effective_model_rollouts_per_step</span><span class="pi">:</span> <span class="m">400</span>
<span class="na">rollout_schedule</span><span class="pi">:</span> <span class="pi">[</span><span class="nv">20</span><span class="pi">,</span> <span class="nv">150</span><span class="pi">,</span> <span class="nv">1</span><span class="pi">,</span> <span class="nv">15</span><span class="pi">]</span>
<span class="na">num_sac_updates_per_step</span><span class="pi">:</span> <span class="m">200000</span>
<span class="na">sac_updates_every_steps</span><span class="pi">:</span> <span class="m">5000</span>
<span class="na">num_epochs_to_retain_sac_buffer</span><span class="pi">:</span> <span class="m">1</span>

<span class="na">sac_gamma</span><span class="pi">:</span> <span class="m">0.99</span>
<span class="na">sac_tau</span><span class="pi">:</span> <span class="m">0.005</span>
<span class="na">sac_alpha</span><span class="pi">:</span> <span class="m">0.2</span>
<span class="na">sac_policy</span><span class="pi">:</span> <span class="s2">"</span><span class="s">Gaussian"</span>
<span class="na">sac_target_update_interval</span><span class="pi">:</span> <span class="m">4</span>
<span class="na">sac_automatic_entropy_tuning</span><span class="pi">:</span> <span class="kc">false</span>
<span class="na">sac_target_entropy</span><span class="pi">:</span> <span class="m">1</span> <span class="c1"># ignored, since entropy tuning is false</span>
<span class="na">sac_hidden_size</span><span class="pi">:</span> <span class="m">512</span>
<span class="na">sac_lr</span><span class="pi">:</span> <span class="m">0.0003</span>
<span class="na">sac_batch_size</span><span class="pi">:</span> <span class="m">256</span>
</code></pre></div></div> <h4 id="walker">Walker</h4> <ul> <li>Update frequency of 1000 steps</li> </ul> <div class="language-yaml highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="c1"># @package _group_</span>
<span class="na">env</span><span class="pi">:</span> <span class="s2">"</span><span class="s">gym___Walker2d-v4"</span>
<span class="na">term_fn</span><span class="pi">:</span> <span class="s2">"</span><span class="s">walker2d"</span>

<span class="na">num_steps</span><span class="pi">:</span> <span class="m">300000</span>
<span class="na">epoch_length</span><span class="pi">:</span> <span class="m">1000</span>
<span class="na">num_elites</span><span class="pi">:</span> <span class="m">5</span>
<span class="na">patience</span><span class="pi">:</span> <span class="m">10</span>
<span class="na">model_lr</span><span class="pi">:</span> <span class="m">0.001</span>
<span class="na">model_wd</span><span class="pi">:</span> <span class="m">0.00001</span>
<span class="na">model_batch_size</span><span class="pi">:</span> <span class="m">256</span>
<span class="na">validation_ratio</span><span class="pi">:</span> <span class="m">0.2</span>
<span class="na">freq_train_model</span><span class="pi">:</span> <span class="m">1000</span>
<span class="na">effective_model_rollouts_per_step</span><span class="pi">:</span> <span class="m">400</span>
<span class="na">rollout_schedule</span><span class="pi">:</span> <span class="pi">[</span><span class="nv">20</span><span class="pi">,</span> <span class="nv">150</span><span class="pi">,</span> <span class="nv">1</span><span class="pi">,</span> <span class="nv">1</span><span class="pi">]</span>
<span class="na">num_sac_updates_per_step</span><span class="pi">:</span> <span class="m">20000</span>
<span class="na">sac_updates_every_steps</span><span class="pi">:</span> <span class="m">1000</span>
<span class="na">num_epochs_to_retain_sac_buffer</span><span class="pi">:</span> <span class="m">1</span>

<span class="na">sac_gamma</span><span class="pi">:</span> <span class="m">0.99</span>
<span class="na">sac_tau</span><span class="pi">:</span> <span class="m">0.005</span>
<span class="na">sac_alpha</span><span class="pi">:</span> <span class="m">0.2</span>
<span class="na">sac_policy</span><span class="pi">:</span> <span class="s2">"</span><span class="s">Gaussian"</span>
<span class="na">sac_target_update_interval</span><span class="pi">:</span> <span class="m">4</span>
<span class="na">sac_automatic_entropy_tuning</span><span class="pi">:</span> <span class="kc">false</span>
<span class="na">sac_target_entropy</span><span class="pi">:</span> <span class="s">-1</span> <span class="c1"># ignored, since entropy tuning is false</span>
<span class="na">sac_hidden_size</span><span class="pi">:</span> <span class="m">1024</span>
<span class="na">sac_lr</span><span class="pi">:</span> <span class="m">0.0001</span>
<span class="na">sac_batch_size</span><span class="pi">:</span> <span class="m">256</span>
</code></pre></div></div> <ul> <li>Update frequency of 5000 steps We only used a maximum buffer size of 1 million to limit the memory usage of this experiment.</li> </ul> <div class="language-yaml highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="c1"># @package _group_</span>
<span class="na">env</span><span class="pi">:</span> <span class="s2">"</span><span class="s">gym___Walker2d-v4"</span>
<span class="na">term_fn</span><span class="pi">:</span> <span class="s2">"</span><span class="s">walker2d"</span>

<span class="na">num_steps</span><span class="pi">:</span> <span class="m">300000</span>
<span class="na">epoch_length</span><span class="pi">:</span> <span class="m">1000</span>
<span class="na">num_elites</span><span class="pi">:</span> <span class="m">5</span>
<span class="na">patience</span><span class="pi">:</span> <span class="m">10</span>
<span class="na">model_lr</span><span class="pi">:</span> <span class="m">0.001</span>
<span class="na">model_wd</span><span class="pi">:</span> <span class="m">0.00001</span>
<span class="na">model_batch_size</span><span class="pi">:</span> <span class="m">256</span>
<span class="na">validation_ratio</span><span class="pi">:</span> <span class="m">0.2</span>
<span class="na">freq_train_model</span><span class="pi">:</span> <span class="m">5000</span>
<span class="na">effective_model_rollouts_per_step</span><span class="pi">:</span> <span class="m">200</span>
<span class="na">rollout_schedule</span><span class="pi">:</span> <span class="pi">[</span><span class="nv">20</span><span class="pi">,</span> <span class="nv">150</span><span class="pi">,</span> <span class="nv">1</span><span class="pi">,</span> <span class="nv">1</span><span class="pi">]</span>
<span class="na">num_sac_updates_per_step</span><span class="pi">:</span> <span class="m">100000</span>
<span class="na">sac_updates_every_steps</span><span class="pi">:</span> <span class="m">5000</span>
<span class="na">num_epochs_to_retain_sac_buffer</span><span class="pi">:</span> <span class="m">1</span>

<span class="na">sac_gamma</span><span class="pi">:</span> <span class="m">0.99</span>
<span class="na">sac_tau</span><span class="pi">:</span> <span class="m">0.005</span>
<span class="na">sac_alpha</span><span class="pi">:</span> <span class="m">0.2</span>
<span class="na">sac_policy</span><span class="pi">:</span> <span class="s2">"</span><span class="s">Gaussian"</span>
<span class="na">sac_target_update_interval</span><span class="pi">:</span> <span class="m">4</span>
<span class="na">sac_automatic_entropy_tuning</span><span class="pi">:</span> <span class="kc">false</span>
<span class="na">sac_target_entropy</span><span class="pi">:</span> <span class="s">-1</span> <span class="c1"># ignored, since entropy tuning is false</span>
<span class="na">sac_hidden_size</span><span class="pi">:</span> <span class="m">1024</span>
<span class="na">sac_lr</span><span class="pi">:</span> <span class="m">0.0001</span>
<span class="na">sac_batch_size</span><span class="pi">:</span> <span class="m">256</span>
</code></pre></div></div> </d-article> <d-appendix> <d-footnote-list></d-footnote-list> <d-citation-list></d-citation-list> </d-appendix> </div> <d-bibliography src="/2024/assets/bibliography/2024-05-07-update-frequency-in-mbrl.bib"></d-bibliography> <d-article id="bibtex-container" class="related highlight"> For attribution in academic contexts, please cite this work as <pre id="bibtex-academic-attribution">
        PLACEHOLDER FOR ACADEMIC ATTRIBUTION
  </pre> BibTeX citation <pre id="bibtex-box">
        PLACEHOLDER FOR BIBTEX
  </pre> </d-article> <script src="https://utteranc.es/client.js" repo="iclr-blogposts/2024" issue-term="pathname" theme="github-light" crossorigin="anonymous" async> </script> <script src="https://cdn.jsdelivr.net/npm/bootstrap@4.6.1/dist/js/bootstrap.bundle.min.js" integrity="sha256-fgLAgv7fyCGopR/gBNq2iW3ZKIdqIcyshnUULC4vex8=" crossorigin="anonymous"></script> <script src="https://cdn.jsdelivr.net/npm/mdbootstrap@4.20.0/js/mdb.min.js" integrity="sha256-NdbiivsvWt7VYCt6hYNT3h/th9vSTL4EDWeGs5SN3DA=" crossorigin="anonymous"></script> </body> </html>